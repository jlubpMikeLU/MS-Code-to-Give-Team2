{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "560db445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T03:01:03.342870Z",
     "iopub.status.busy": "2025-06-26T03:01:03.342586Z",
     "iopub.status.idle": "2025-06-26T03:01:03.347343Z",
     "shell.execute_reply": "2025-06-26T03:01:03.346925Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install together opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "205250ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining paths for images and ouputs\n",
    "\n",
    "#input_images\n",
    "image_url_terminal = \"./Screenshots/Terminal.png\"\n",
    "image_url_excel = \"./Screenshots/Excel.png\"\n",
    "image_url_chrome = \"./Screenshots/Chrome.png\"\n",
    "image_path_pdf = \"./Screenshots/PDF.png\"\n",
    "image_path_powershell_error = \"./Screenshots/Powershell_error.png\"\n",
    "image_path_powershell_success = \"./Screenshots/Powershell_error_free.png\"\n",
    "\n",
    "#input_videos\n",
    "video_path_coding_vba = \"./VidRecordings/CodingVBA_sample.mp4\"\n",
    "\n",
    "#output_images\n",
    "output_pdf = \"./Outputs/analysis_output_pdf.md\"\n",
    "output_powershell_error = \"./Outputs/analysis_output_powershell_error_nonAdmin.md\"\n",
    "output_powershell_success = \"./Outputs/analysis_output_powershell_Admin.md\"\n",
    "output_terminal = \"./Outputs/analysis_output_terminal.md\"\n",
    "output_excel = \"./Outputs/analysis_output_excel.md\"\n",
    "output_chrome = \"./Outputs/analysis_output_chrome.md\"\n",
    "\n",
    "#output_videos\n",
    "output_video_coding_vba = \"./Outputs/analysis_output_coding_vba.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a2166b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T03:01:03.349031Z",
     "iopub.status.busy": "2025-06-26T03:01:03.348882Z",
     "iopub.status.idle": "2025-06-26T03:01:10.240262Z",
     "shell.execute_reply": "2025-06-26T03:01:10.239067Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import os\n",
    "from nbconvert import export\n",
    "import requests\n",
    "from together import Together\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import json\n",
    "\n",
    "os.environ[\"TOGETHER_API_KEY\"] = \"tgp_v1_DgIeKD-5c-MS2fxBpr5VO8hIB1TeUgun-Nk7Y5b9o98\"\n",
    "\n",
    "# Initialize Together AI client (set API key as environment variable or replace here)\n",
    "# os.environ[\"TOGETHER_API_KEY\"] = \"your_api_key_here\"\n",
    "client = Together()\n",
    "\n",
    "def load_image(image_source, is_url=False):\n",
    "    \"\"\"\n",
    "    Load an image from a URL or local file and return it as a base64-encoded string with content type.\n",
    "    \n",
    "    Args:\n",
    "        image_source (str): URL or local file path to the image.\n",
    "        is_url (bool): True if image_source is a URL, False if local file.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (base64-encoded image string, content type)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if is_url:\n",
    "            response = requests.get(image_source, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            content_type = response.headers.get('Content-Type', 'image/jpeg')\n",
    "            format = content_type.split('/')[-1].lower()\n",
    "        else:\n",
    "            format = os.path.splitext(image_source)[1][1:].lower()\n",
    "            if format not in ['jpeg', 'jpg', 'png']:\n",
    "                format = 'jpeg'\n",
    "            img = Image.open(image_source)\n",
    "            content_type = f\"image/{format}\"\n",
    "        \n",
    "        buffer = BytesIO()\n",
    "        img.save(buffer, format=format)\n",
    "        img_str = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "        return img_str, content_type\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to load image: {e}\")\n",
    "\n",
    "def generate_image_summary(image_source, is_url=False, max_tokens=5000):\n",
    "    \"\"\"\n",
    "    Generate a summary of an image using Llama 4 Maverick via Together AI API.\n",
    "    \n",
    "    Args:\n",
    "        image_source (str): URL or local file path to the image.\n",
    "        is_url (bool): True if image_source is a URL, False if local file.\n",
    "        max_tokens (int): Maximum tokens for the summary.\n",
    "    \n",
    "    Returns:\n",
    "        str: Summary of the image.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \"\"\"You are an expert computer vision analyst specializing in desktop environment analysis. Examine the provided screenshot with meticulous attention to detail and deliver your analysis in the following JSON format:\n",
    "\n",
    "        {\n",
    "            \"applications_open\": [\"comprehensive list of ALL visible applications, software, and browser tabs in the screenshot\"],\n",
    "            \"text_content\": [\"ALL readable text visible in the screenshot, including application names, window titles, menu items, document content, code snippets, terminal commands, browser content, notifications, taskbar information, and any other visible text elements\"],\n",
    "            \"summary\": \"A comprehensive yet concise analysis that integrates all observations from applications_open and text_content into a cohesive narrative. Describe what the user appears to be working on, the relationship between open applications, and provide context for the visible content. This summary must be detailed enough to stand alone as a complete analysis of the screenshot.\"\n",
    "        }\n",
    "\n",
    "        Analysis guidelines:\n",
    "        1. Be exhaustive in identifying ALL open applications - include minimized apps in taskbars, system trays, docks, browser tabs, and background processes with visual indicators\n",
    "        2. Capture ALL visible text regardless of size or prominence - include menu items, file paths, code, commands, URLs, and partial text if readable\n",
    "        3. When analyzing code or technical content, note the programming language, frameworks, or technologies in use\n",
    "        4. Pay attention to timestamps, usernames, file names, and other contextual information\n",
    "        5. Consider the relationship between open applications to infer the user's workflow\n",
    "        6. In the summary, reconstruct the likely sequence of the user's activities based on the visible evidence\n",
    "\n",
    "        Image data: data:image/png;base64,{base64_image}\n",
    "\n",
    "        Provide only the JSON response without any introduction or additional text.\"\"\"\n",
    "\n",
    "    img_base64, content_type = load_image(image_source, is_url)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:{content_type};base64,{img_base64}\"}}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\",\n",
    "        messages=messages,\n",
    "        temperature=0.3,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffceeed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def extract_significant_frames(\n",
    "    video_path: str, \n",
    "    difference_threshold: float = 0.1,\n",
    "    min_frame_interval: int = 5,\n",
    "    max_frames: int = 100,\n",
    "    resize_factor: float = 0.5\n",
    ") -> Tuple[List[Tuple[int, float, float]], dict]:\n",
    "    \"\"\"\n",
    "    Extract significant frame metadata from a video using frame differencing.\n",
    "    Uses resized frames for fast processing but returns metadata for high-quality extraction.\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to the input video file\n",
    "        difference_threshold (float): Threshold for considering frames significantly different (0-1)\n",
    "        min_frame_interval (int): Minimum number of frames between significant frames\n",
    "        max_frames (int): Maximum number of significant frames to extract\n",
    "        resize_factor (float): Factor to resize frames for faster processing (doesn't affect output quality)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[List[Tuple[int, float, float]], dict]: \n",
    "            - List of (frame_number, timestamp, difference_score)\n",
    "            - Video metadata dict with fps, total_frames, etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Error opening video file: {video_path}\")\n",
    "    \n",
    "    # Get video properties\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    duration = total_frames / fps if fps > 0 else 0\n",
    "    \n",
    "    video_metadata = {\n",
    "        'fps': fps,\n",
    "        'total_frames': total_frames,\n",
    "        'duration': duration,\n",
    "        'video_path': video_path\n",
    "    }\n",
    "    \n",
    "    print(f\"Video info: {total_frames} frames, {fps:.2f} FPS, {duration:.1f}s duration\")\n",
    "    \n",
    "    significant_frame_metadata = []\n",
    "    prev_gray = None\n",
    "    last_significant_frame = -min_frame_interval\n",
    "    frame_count = 0\n",
    "    \n",
    "    # Read first frame\n",
    "    ret, prev_frame = cap.read()\n",
    "    if not ret:\n",
    "        raise ValueError(\"Could not read the first frame\")\n",
    "    \n",
    "    # Resize for faster processing (this doesn't affect final output quality)\n",
    "    if resize_factor != 1.0:\n",
    "        prev_frame_resized = cv2.resize(prev_frame, None, fx=resize_factor, fy=resize_factor)\n",
    "    else:\n",
    "        prev_frame_resized = prev_frame\n",
    "    \n",
    "    prev_gray = cv2.cvtColor(prev_frame_resized, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Add first frame as significant\n",
    "    timestamp = 0.0\n",
    "    significant_frame_metadata.append((0, timestamp, 1.0))\n",
    "    \n",
    "    print(\"Processing frames for significant changes...\")\n",
    "    \n",
    "    while True:\n",
    "        ret, current_frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        timestamp = frame_count / fps if fps > 0 else 0\n",
    "        \n",
    "        # Resize for faster processing only\n",
    "        if resize_factor != 1.0:\n",
    "            current_frame_resized = cv2.resize(current_frame, None, fx=resize_factor, fy=resize_factor)\n",
    "        else:\n",
    "            current_frame_resized = current_frame\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        current_gray = cv2.cvtColor(current_frame_resized, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Calculate frame difference\n",
    "        frame_diff = cv2.absdiff(prev_gray, current_gray)\n",
    "        \n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        frame_diff_blur = cv2.GaussianBlur(frame_diff, (5, 5), 0)\n",
    "        \n",
    "        # Calculate percentage of changed pixels\n",
    "        _, thresh = cv2.threshold(frame_diff_blur, 25, 255, cv2.THRESH_BINARY)\n",
    "        changed_pixels = cv2.countNonZero(thresh)\n",
    "        total_pixels = thresh.shape[0] * thresh.shape[1]\n",
    "        change_percentage = changed_pixels / total_pixels\n",
    "        \n",
    "        # Check if frame is significantly different and meets interval requirement\n",
    "        if (change_percentage > difference_threshold and \n",
    "            frame_count - last_significant_frame >= min_frame_interval):\n",
    "            \n",
    "            significant_frame_metadata.append((frame_count, timestamp, change_percentage))\n",
    "            last_significant_frame = frame_count\n",
    "            \n",
    "            print(f\"Significant frame found: Frame {frame_count}, Time: {timestamp:.2f}s, Change: {change_percentage:.3f}\")\n",
    "            \n",
    "            # Stop if we've reached max frames\n",
    "            if len(significant_frame_metadata) >= max_frames:\n",
    "                print(f\"Reached maximum frames limit ({max_frames})\")\n",
    "                break\n",
    "        \n",
    "        # Update previous frame\n",
    "        prev_gray = current_gray.copy()\n",
    "        \n",
    "        # Print progress\n",
    "        if frame_count % 1000 == 0:\n",
    "            progress = (frame_count / total_frames) * 100\n",
    "            print(f\"Progress: {progress:.1f}% ({frame_count}/{total_frames})\")\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    print(f\"Extracted {len(significant_frame_metadata)} significant frame timestamps from {total_frames} total frames\")\n",
    "    print(f\"Frame reduction: {((total_frames - len(significant_frame_metadata)) / total_frames) * 100:.1f}%\")\n",
    "    \n",
    "    return significant_frame_metadata, video_metadata\n",
    "\n",
    "def extract_high_quality_frames_from_video(\n",
    "    video_path: str,\n",
    "    frame_metadata: List[Tuple[int, float, float]],\n",
    "    output_dir: str = \"./temp_frames\"\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract high-quality frames from video using frame numbers/timestamps.\n",
    "    This ensures maximum quality for AI analysis.\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to the input video file\n",
    "        frame_metadata: List of (frame_number, timestamp, difference_score)\n",
    "        output_dir: Directory to save frame images\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: List of saved high-quality image file paths\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Error opening video file: {video_path}\")\n",
    "    \n",
    "    image_paths = []\n",
    "    total_frames_to_extract = len(frame_metadata)\n",
    "    \n",
    "    print(f\"Extracting {total_frames_to_extract} high-quality frames from original video...\")\n",
    "    \n",
    "    for i, (frame_num, timestamp, diff_score) in enumerate(frame_metadata):\n",
    "        # Set video position to specific frame\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"Warning: Could not read frame {frame_num}\")\n",
    "            continue\n",
    "        \n",
    "        # Create filename\n",
    "        filename = f\"frame_{frame_num:06d}_diff_{diff_score:.3f}.png\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        # Save high-quality image directly using OpenCV (preserves original quality)\n",
    "        # Use PNG for lossless compression\n",
    "        success = cv2.imwrite(filepath, frame, [cv2.IMWRITE_PNG_COMPRESSION, 1])\n",
    "        \n",
    "        if success:\n",
    "            image_paths.append(filepath)\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"  Extracted {i + 1}/{total_frames_to_extract} high-quality frames\")\n",
    "        else:\n",
    "            print(f\"Warning: Failed to save frame {frame_num}\")\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    print(f\"Successfully saved {len(image_paths)} high-quality frame images to {output_dir}\")\n",
    "    return image_paths\n",
    "\n",
    "def save_frames_as_images(frames_data: List[Tuple[int, float, float]], \n",
    "                         video_path: str,\n",
    "                         output_dir: str = \"./temp_frames\") -> List[str]:\n",
    "    \"\"\"\n",
    "    Legacy wrapper function for backward compatibility.\n",
    "    Now uses high-quality frame extraction method.\n",
    "    \n",
    "    Args:\n",
    "        frames_data: List of (frame_number, timestamp, difference_score)\n",
    "        video_path: Path to the original video file\n",
    "        output_dir: Directory to save frame images\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: List of saved image file paths\n",
    "    \"\"\"\n",
    "    \n",
    "    return extract_high_quality_frames_from_video(video_path, frames_data, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5355718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T03:01:10.244731Z",
     "iopub.status.busy": "2025-06-26T03:01:10.244353Z",
     "iopub.status.idle": "2025-06-26T03:01:10.257808Z",
     "shell.execute_reply": "2025-06-26T03:01:10.257035Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def convert_output_to_json(output_str):\n",
    "    \"\"\"\n",
    "    Convert the output string to a JSON object with robust error handling.\n",
    "    \n",
    "    Args:\n",
    "        output_str (str): The string containing the JSON-like data structure\n",
    "        \n",
    "    Returns:\n",
    "        dict: A properly formatted JSON object\n",
    "    \"\"\"\n",
    "    # First try direct JSON parsing if the output is a valid JSON\n",
    "    if output_str.strip().startswith(\"{\") and output_str.strip().endswith(\"}\"):\n",
    "        try:\n",
    "            # Handle potential code block markers\n",
    "            clean_str = output_str.strip()\n",
    "            if clean_str.startswith(\"```\") and clean_str.endswith(\"```\"):\n",
    "                clean_str = clean_str[3:-3].strip()\n",
    "                if clean_str.startswith(\"json\"):\n",
    "                    clean_str = clean_str[4:].strip()\n",
    "            \n",
    "            return json.loads(clean_str)\n",
    "        except json.JSONDecodeError:\n",
    "            pass  # Continue with regex-based parsing\n",
    "    \n",
    "    # Create an empty result structure\n",
    "    result = {\n",
    "        \"applications_open\": [],\n",
    "        \"text_content\": [],\n",
    "        \"summary\": \"\"\n",
    "    }\n",
    "    \n",
    "    # Extract applications_open array\n",
    "    apps_match = re.search(r'\"applications_open\":\\s*\\[(.*?)\\]', output_str, re.DOTALL)\n",
    "    if apps_match:\n",
    "        apps_str = apps_match.group(1).strip()\n",
    "        # Parse the array items\n",
    "        if apps_str:\n",
    "            apps_items = re.findall(r'\"((?:\\\\.|[^\"\\\\])*)\"', apps_str)\n",
    "            result[\"applications_open\"] = [item.replace('\\\\\\\"', '\"').replace('\\\\\\\\', '\\\\') for item in apps_items]\n",
    "    \n",
    "    # Extract text_content array - try a even more robust approach that captures all text content items\n",
    "    # First try to match the full content between array brackets\n",
    "    text_match = re.search(r'\"text_content\":\\s*\\[([\\s\\S]*?)\\],\\s*\"summary\":', output_str)\n",
    "    if text_match:\n",
    "        text_content_raw = text_match.group(1).strip()\n",
    "        \n",
    "        # Parse each string item in the array\n",
    "        text_items = []\n",
    "        \n",
    "        # Use a custom string parsing approach to handle nested quotes correctly\n",
    "        in_string = False\n",
    "        current_item = \"\"\n",
    "        escape_next = False\n",
    "        \n",
    "        for char in text_content_raw:\n",
    "            if escape_next:\n",
    "                current_item += char\n",
    "                escape_next = False\n",
    "                continue\n",
    "                \n",
    "            if char == '\\\\':\n",
    "                escape_next = True\n",
    "                current_item += char\n",
    "                continue\n",
    "                \n",
    "            if char == '\"' and not escape_next:\n",
    "                if not in_string:\n",
    "                    in_string = True  # Starting a string\n",
    "                    current_item = \"\"  # Reset the current item\n",
    "                else:\n",
    "                    in_string = False  # Ending a string\n",
    "                    if current_item:  # Add the completed item if it's not empty\n",
    "                        text_items.append(current_item.replace('\\\\\\\"', '\"').replace('\\\\\\\\', '\\\\'))\n",
    "                continue\n",
    "                \n",
    "            if in_string:  # Only collect characters when inside a string\n",
    "                current_item += char\n",
    "                \n",
    "        # If that failed, try the regex-based approach as a fallback\n",
    "        if not text_items:\n",
    "            string_pattern = re.compile(r'\"((?:\\\\.|[^\"\\\\])*)\"')\n",
    "            pos = 0\n",
    "            \n",
    "            # Find all strings in the text content section\n",
    "            while pos < len(text_content_raw):\n",
    "                match = string_pattern.search(text_content_raw, pos)\n",
    "                if not match:\n",
    "                    break\n",
    "                    \n",
    "                text_items.append(match.group(1).replace('\\\\\\\"', '\"').replace('\\\\\\\\', '\\\\'))\n",
    "                pos = match.end()\n",
    "                \n",
    "        result[\"text_content\"] = text_items\n",
    "    \n",
    "    # Extract summary\n",
    "    summary_match = re.search(r'\"summary\":\\s*\"((?:\\\\.|[^\"\\\\])*)\"', output_str, re.DOTALL)\n",
    "    if summary_match:\n",
    "        summary = summary_match.group(1).replace('\\\\\\\"', '\"').replace('\\\\\\\\', '\\\\')\n",
    "        result[\"summary\"] = summary\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f308f21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T03:01:10.260634Z",
     "iopub.status.busy": "2025-06-26T03:01:10.260386Z",
     "iopub.status.idle": "2025-06-26T03:01:10.275045Z",
     "shell.execute_reply": "2025-06-26T03:01:10.274525Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Union, Dict, List, Any\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def json_to_markdown(\n",
    "    json_data: Union[str, Dict[str, Any]], \n",
    "    output_file: str = \"analysis_output_excel.md\",\n",
    "    username: str = \"Aarav\",\n",
    "    timestamp: str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Convert JSON data to a nicely formatted Markdown file.\n",
    "    \n",
    "    Args:\n",
    "        json_data: Either a JSON string or a parsed JSON object containing analysis data\n",
    "        output_file: Path/name of the output markdown file\n",
    "        username: Current user's login (optional)\n",
    "        timestamp: Current timestamp (optional)\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the created markdown file\n",
    "    \"\"\"\n",
    "    # Parse JSON if a string is provided\n",
    "    if isinstance(json_data, str):\n",
    "        # Try to parse it directly first\n",
    "        try:\n",
    "            # Clean string of code block markers if present\n",
    "            clean_str = json_data.strip()\n",
    "            if clean_str.startswith(\"```\") and clean_str.endswith(\"```\"):\n",
    "                clean_str = clean_str[3:-3].strip()\n",
    "                if clean_str.startswith(\"json\"):\n",
    "                    clean_str = clean_str[4:].strip()\n",
    "                    \n",
    "            data = json.loads(clean_str)\n",
    "        except json.JSONDecodeError:\n",
    "            # If the standard parsing fails, use our custom parser\n",
    "            data = convert_output_to_json(json_data)\n",
    "    else:\n",
    "        data = json_data\n",
    "    \n",
    "    # Create markdown content\n",
    "    md_content = []\n",
    "    \n",
    "    # Add title and metadata\n",
    "    md_content.append(\"# Desktop Screenshot Analysis\\n\")\n",
    "    \n",
    "    if timestamp or username:\n",
    "        md_content.append(\"## Metadata\\n\")\n",
    "        if timestamp:\n",
    "            md_content.append(f\"**Timestamp:** {timestamp}\\n\")\n",
    "        if username:\n",
    "            md_content.append(f\"**User:** {username}\\n\")\n",
    "        md_content.append(\"\\n\")\n",
    "    \n",
    "    # Add applications section\n",
    "    md_content.append(\"## Applications Open\\n\")\n",
    "    if data.get(\"applications_open\"):\n",
    "        for app in data[\"applications_open\"]:\n",
    "            md_content.append(f\"- {app}\\n\")\n",
    "    else:\n",
    "        md_content.append(\"*No applications detected*\\n\")\n",
    "    md_content.append(\"\\n\")\n",
    "    \n",
    "    # Add text content section\n",
    "    md_content.append(\"## Text Content\\n\")\n",
    "    if data.get(\"text_content\"):\n",
    "        md_content.append(\"```\\n\")  # Start code block\n",
    "        for text_item in data[\"text_content\"]:\n",
    "            md_content.append(f\"{text_item}\\n\")\n",
    "        md_content.append(\"```\\n\")  # End code block\n",
    "    else:\n",
    "        md_content.append(\"*No text content detected*\\n\")\n",
    "    md_content.append(\"\\n\")\n",
    "    \n",
    "    # Add summary section\n",
    "    md_content.append(\"## Summary\\n\")\n",
    "    if data.get(\"summary\"):\n",
    "        md_content.append(f\"{data['summary']}\\n\")\n",
    "    else:\n",
    "        md_content.append(\"*No summary available*\\n\")\n",
    "    \n",
    "    # Write to file\n",
    "    try:\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(''.join(md_content))\n",
    "        print(f\"Successfully created Markdown file: {output_file}\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error writing to file: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80515ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated function with video metadata support\n",
    "def generate_video_analysis_report_updated(analyses: List[dict], video_path: str, username: str, video_metadata: dict = None) -> str:\n",
    "    \"\"\"\n",
    "    Generate a comprehensive markdown report from frame analyses.\n",
    "    Updated to support video metadata and timestamps.\n",
    "    \n",
    "    Args:\n",
    "        analyses: List of frame analysis dictionaries\n",
    "        video_path: Path to the original video\n",
    "        username: Username for the report\n",
    "        video_metadata: Optional video metadata dictionary with fps, duration, etc.\n",
    "        \n",
    "    Returns:\n",
    "        str: Markdown report content\n",
    "    \"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    report = []\n",
    "    \n",
    "    # Header\n",
    "    report.append(\"# High-Quality Video Screen Recording Analysis Report\\n\\n\")\n",
    "    \n",
    "    # Metadata section\n",
    "    report.append(\"## Analysis Metadata\\n\\n\")\n",
    "    report.append(f\"**Video File:** `{os.path.basename(video_path)}`\\n\")\n",
    "    report.append(f\"**Analysis Timestamp:** {timestamp}\\n\")\n",
    "    report.append(f\"**User:** {username}\\n\")\n",
    "    report.append(f\"**Frames Analyzed:** {len(analyses)}\\n\")\n",
    "    \n",
    "    if video_metadata:\n",
    "        report.append(f\"**Video FPS:** {video_metadata.get('fps', 'Unknown'):.2f}\\n\")\n",
    "        report.append(f\"**Video Duration:** {video_metadata.get('duration', 'Unknown'):.1f}s\\n\")\n",
    "        report.append(f\"**Total Video Frames:** {video_metadata.get('total_frames', 'Unknown')}\\n\")\n",
    "    \n",
    "    report.append(f\"**Analysis Method:** High-Quality Frame Differencing + AI Vision Analysis\\n\")\n",
    "    report.append(f\"**Frame Quality:** Full Resolution (No Degradation)\\n\\n\")\n",
    "    \n",
    "    # Executive Summary\n",
    "    report.append(\"## Executive Summary\\n\\n\")\n",
    "    \n",
    "    # Extract key applications and activities\n",
    "    all_applications = set()\n",
    "    all_text_content = []\n",
    "    activity_timeline = []\n",
    "    \n",
    "    for analysis in analyses:\n",
    "        frame_analysis = analysis['analysis']\n",
    "        frame_num = analysis['frame_number']\n",
    "        timestamp_val = analysis.get('timestamp', 0)\n",
    "        diff_score = analysis['difference_score']\n",
    "        \n",
    "        # Collect applications\n",
    "        if frame_analysis.get('applications_open'):\n",
    "            all_applications.update(frame_analysis['applications_open'])\n",
    "        \n",
    "        # Collect text content\n",
    "        if frame_analysis.get('text_content'):\n",
    "            all_text_content.extend(frame_analysis['text_content'])\n",
    "        \n",
    "        # Create timeline entry with timestamp\n",
    "        if frame_analysis.get('summary'):\n",
    "            activity_timeline.append(f\"**Frame {frame_num}** at {timestamp_val:.2f}s (Change: {diff_score:.3f}): {frame_analysis['summary'][:200]}...\")\n",
    "    \n",
    "    report.append(f\"This high-quality analysis covers {len(analyses)} significant frames extracted from the screen recording. \")\n",
    "    report.append(f\"The user was observed working with {len(all_applications)} different applications/tools. \")\n",
    "    \n",
    "    if video_metadata:\n",
    "        total_frames = video_metadata.get('total_frames', 1)\n",
    "        reduction_percent = ((total_frames - len(analyses)) / total_frames) * 100\n",
    "        report.append(f\"Frame reduction achieved: {reduction_percent:.1f}% (from {total_frames} to {len(analyses)} frames). \")\n",
    "    \n",
    "    report.append(\"The following report provides detailed insights into user activities and potential security considerations.\\n\\n\")\n",
    "    \n",
    "    # Applications used\n",
    "    report.append(\"## Applications and Tools Used\\n\\n\")\n",
    "    if all_applications:\n",
    "        for app in sorted(all_applications):\n",
    "            report.append(f\"- {app}\\n\")\n",
    "    else:\n",
    "        report.append(\"*No applications detected*\\n\")\n",
    "    report.append(\"\\n\")\n",
    "    \n",
    "    # Activity Timeline\n",
    "    report.append(\"## Activity Timeline\\n\\n\")\n",
    "    for activity in activity_timeline[:10]:  # Limit to first 10 for brevity\n",
    "        report.append(f\"{activity}\\n\\n\")\n",
    "    \n",
    "    if len(activity_timeline) > 10:\n",
    "        report.append(f\"*... and {len(activity_timeline) - 10} more activities*\\n\\n\")\n",
    "    \n",
    "    # Detailed Frame Analysis\n",
    "    report.append(\"## Detailed Frame Analysis\\n\\n\")\n",
    "    \n",
    "    for i, analysis in enumerate(analyses):\n",
    "        frame_num = analysis['frame_number']\n",
    "        timestamp_val = analysis.get('timestamp', 0)\n",
    "        diff_score = analysis['difference_score']\n",
    "        frame_analysis = analysis['analysis']\n",
    "        \n",
    "        report.append(f\"### Frame {frame_num} at {timestamp_val:.2f}s (Significance Score: {diff_score:.3f})\\n\\n\")\n",
    "        \n",
    "        # Applications in this frame\n",
    "        if frame_analysis.get('applications_open'):\n",
    "            report.append(\"**Applications:**\\n\")\n",
    "            for app in frame_analysis['applications_open']:\n",
    "                report.append(f\"- {app}\\n\")\n",
    "            report.append(\"\\n\")\n",
    "        \n",
    "        # Text content\n",
    "        if frame_analysis.get('text_content'):\n",
    "            report.append(\"**Visible Text Content:**\\n\")\n",
    "            report.append(\"```\\n\")\n",
    "            for text in frame_analysis['text_content'][:20]:  # Limit to first 20 items\n",
    "                report.append(f\"{text}\\n\")\n",
    "            if len(frame_analysis['text_content']) > 20:\n",
    "                report.append(f\"... and {len(frame_analysis['text_content']) - 20} more text elements\\n\")\n",
    "            report.append(\"```\\n\\n\")\n",
    "        \n",
    "        # Summary\n",
    "        if frame_analysis.get('summary'):\n",
    "            report.append(f\"**Analysis:** {frame_analysis['summary']}\\n\\n\")\n",
    "        \n",
    "        report.append(\"---\\n\\n\")\n",
    "    \n",
    "    # Quality assurance section\n",
    "    report.append(\"## Quality Assurance\\n\\n\")\n",
    "    report.append(\"**Frame Extraction Quality:** High\\n\")\n",
    "    report.append(\"- Frames extracted at full video resolution\\n\")\n",
    "    report.append(\"- No quality loss from resizing or format conversion\\n\")\n",
    "    report.append(\"- Lossless PNG compression used for storage\\n\")\n",
    "    report.append(\"- Original video color space preserved\\n\\n\")\n",
    "    \n",
    "    # Security considerations\n",
    "    report.append(\"## Security and Compliance Notes\\n\\n\")\n",
    "    report.append(\"This analysis was performed for access management and security monitoring purposes. \")\n",
    "    report.append(\"Key observations:\\n\\n\")\n",
    "    report.append(f\"- Total significant activity changes detected: {len(analyses)}\\n\")\n",
    "    report.append(f\"- Applications accessed: {len(all_applications)}\\n\")\n",
    "    report.append(\"- All activities have been logged and analyzed for compliance\\n\")\n",
    "    report.append(\"- High-quality frame analysis ensures maximum detection accuracy\\n\")\n",
    "    report.append(\"- This report should be reviewed by authorized personnel only\\n\\n\")\n",
    "    \n",
    "    return ''.join(report)\n",
    "\n",
    "# Alias the updated function to replace the old one\n",
    "generate_video_analysis_report = generate_video_analysis_report_updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42be0ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def analyze_frame_with_retry(image_path: str, max_retries: int = 3, sleep_duration: int = 65) -> dict:\n",
    "    \"\"\"\n",
    "    Analyze a frame with retry logic for rate limiting.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        max_retries: Maximum number of retry attempts\n",
    "        sleep_duration: Sleep duration in seconds when rate limited\n",
    "        \n",
    "    Returns:\n",
    "        dict: Analysis result or None if all retries failed\n",
    "    \"\"\"\n",
    "    \n",
    "    for attempt in range(max_retries + 1):\n",
    "        try:\n",
    "            # Generate summary for this frame\n",
    "            summary = generate_image_summary(image_path, is_url=False)\n",
    "            \n",
    "            # Convert to JSON\n",
    "            summary_json = convert_output_to_json(summary)\n",
    "            \n",
    "            return summary_json\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_str = str(e)\n",
    "            \n",
    "            # Check if it's a rate limit error (429)\n",
    "            if \"429\" in error_str and \"rate limit\" in error_str.lower():\n",
    "                if attempt < max_retries:\n",
    "                    print(f\"    ⏳ Rate limit hit (attempt {attempt + 1}/{max_retries + 1}). Sleeping for {sleep_duration} seconds...\")\n",
    "                    time.sleep(sleep_duration)\n",
    "                    print(f\"    🔄 Retrying frame analysis...\")\n",
    "                else:\n",
    "                    print(f\"    ❌ Rate limit exceeded after {max_retries + 1} attempts. Skipping frame.\")\n",
    "                    return None\n",
    "            else:\n",
    "                # Non-rate-limit error, don't retry\n",
    "                print(f\"    ❌ Non-rate-limit error: {error_str}\")\n",
    "                return None\n",
    "    \n",
    "    return None\n",
    "\n",
    "def process_video_with_frame_differencing(\n",
    "    video_path: str,\n",
    "    output_markdown_path: str,\n",
    "    difference_threshold: float = 0.1,\n",
    "    min_frame_interval: int = 5,\n",
    "    max_frames: int = 100,\n",
    "    cleanup_temp_files: bool = False,\n",
    "    username: str = \"User\",\n",
    "    resize_factor: float = 1,\n",
    "    max_retries: int = 2,\n",
    "    sleep_duration: int = 70\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Complete pipeline to process a video with frame differencing and Llama4 Maverick analysis.\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to input video file\n",
    "        output_markdown_path (str): Path for output markdown file\n",
    "        difference_threshold (float): Threshold for frame difference detection\n",
    "        min_frame_interval (int): Minimum frames between significant frames\n",
    "        max_frames (int): Maximum number of frames to analyze\n",
    "        cleanup_temp_files (bool): Whether to delete temporary frame files\n",
    "        username (str): Username for the analysis report\n",
    "        resize_factor (float): Factor to resize frames for processing\n",
    "        max_retries (int): Maximum retry attempts for rate limited requests\n",
    "        sleep_duration (int): Sleep duration in seconds when rate limited\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the generated markdown report\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"STARTING VIDEO ANALYSIS WITH FRAME DIFFERENCING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Extract significant frames\n",
    "        print(\"\\n1. Extracting significant frames from video...\")\n",
    "        significant_frames = extract_significant_frames(\n",
    "            video_path, \n",
    "            difference_threshold=difference_threshold,\n",
    "            min_frame_interval=min_frame_interval,\n",
    "            max_frames=max_frames,\n",
    "            resize_factor=resize_factor\n",
    "        )\n",
    "        \n",
    "        if not significant_frames:\n",
    "            raise ValueError(\"No significant frames extracted from video\")\n",
    "        \n",
    "        # Step 2: Save frames as temporary images\n",
    "        print(\"\\n2. Saving frames as temporary images...\")\n",
    "        temp_dir = \"./temp_frames\"\n",
    "        frame_image_paths = save_frames_as_images(significant_frames, temp_dir)\n",
    "        \n",
    "        # Step 3: Analyze each significant frame with Llama4 Maverick\n",
    "        print(\"\\n3. Analyzing frames with Llama4 Maverick...\")\n",
    "        print(f\"   Rate limiting protection: {max_retries} retries, {sleep_duration}s sleep\")\n",
    "        all_analyses = []\n",
    "        \n",
    "        for i, image_path in enumerate(frame_image_paths):\n",
    "            print(f\"\\n📸 Analyzing frame {i+1}/{len(frame_image_paths)}: {os.path.basename(image_path)}\")\n",
    "            \n",
    "            # Use retry-enabled analysis\n",
    "            summary_json = analyze_frame_with_retry(\n",
    "                image_path, \n",
    "                max_retries=max_retries, \n",
    "                sleep_duration=sleep_duration\n",
    "            )\n",
    "            \n",
    "            if summary_json is not None:\n",
    "                # Add frame metadata\n",
    "                frame_data = significant_frames[i]\n",
    "                frame_number = frame_data[1]\n",
    "                diff_score = frame_data[2]\n",
    "                \n",
    "                frame_analysis = {\n",
    "                    \"frame_number\": frame_number,\n",
    "                    \"difference_score\": diff_score,\n",
    "                    \"image_path\": image_path,\n",
    "                    \"analysis\": summary_json\n",
    "                }\n",
    "                \n",
    "                all_analyses.append(frame_analysis)\n",
    "                \n",
    "                print(f\"  ✅ Frame {frame_number} analyzed successfully (diff: {diff_score:.3f})\")\n",
    "                \n",
    "            else:\n",
    "                # Frame analysis failed after all retries\n",
    "                frame_data = significant_frames[i]\n",
    "                frame_number = frame_data[1]\n",
    "                diff_score = frame_data[2]\n",
    "                print(f\"  ❌ Frame {frame_number} analysis failed after retries (diff: {diff_score:.3f})\")\n",
    "                continue\n",
    "        \n",
    "        # Step 4: Generate comprehensive report\n",
    "        print(\"\\n4. Generating comprehensive analysis report...\")\n",
    "        report_content = generate_video_analysis_report(all_analyses, video_path, username)\n",
    "        \n",
    "        # Step 5: Save report\n",
    "        with open(output_markdown_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(report_content)\n",
    "        \n",
    "        print(f\"\\n✓ Analysis complete! Report saved to: {output_markdown_path}\")\n",
    "        \n",
    "        # Step 6: Cleanup temporary files\n",
    "        if cleanup_temp_files:\n",
    "            print(\"\\n5. Cleaning up temporary files...\")\n",
    "            try:\n",
    "                shutil.rmtree(temp_dir)\n",
    "                print(\"  ✓ Temporary files cleaned up\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ⚠ Warning: Could not clean up temp files: {str(e)}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"VIDEO ANALYSIS COMPLETED SUCCESSFULLY\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return output_markdown_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error during video analysis: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def generate_video_analysis_report(analyses: List[dict], video_path: str, username: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a comprehensive markdown report from frame analyses.\n",
    "    \n",
    "    Args:\n",
    "        analyses: List of frame analysis dictionaries\n",
    "        video_path: Path to the original video\n",
    "        username: Username for the report\n",
    "        \n",
    "    Returns:\n",
    "        str: Markdown report content\n",
    "    \"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    report = []\n",
    "    \n",
    "    # Header\n",
    "    report.append(\"# Video Screen Recording Analysis Report\\n\\n\")\n",
    "    \n",
    "    # Metadata section\n",
    "    report.append(\"## Analysis Metadata\\n\\n\")\n",
    "    report.append(f\"**Video File:** `{os.path.basename(video_path)}`\\n\")\n",
    "    report.append(f\"**Analysis Timestamp:** {timestamp}\\n\")\n",
    "    report.append(f\"**User:** {username}\\n\")\n",
    "    report.append(f\"**Frames Analyzed:** {len(analyses)}\\n\")\n",
    "    report.append(f\"**Analysis Method:** Frame Differencing + AI Vision Analysis\\n\\n\")\n",
    "    \n",
    "    # Executive Summary\n",
    "    report.append(\"## Executive Summary\\n\\n\")\n",
    "    \n",
    "    # Extract key applications and activities\n",
    "    all_applications = set()\n",
    "    all_text_content = []\n",
    "    activity_timeline = []\n",
    "    \n",
    "    for analysis in analyses:\n",
    "        frame_analysis = analysis['analysis']\n",
    "        frame_num = analysis['frame_number']\n",
    "        diff_score = analysis['difference_score']\n",
    "        \n",
    "        # Collect applications\n",
    "        if frame_analysis.get('applications_open'):\n",
    "            all_applications.update(frame_analysis['applications_open'])\n",
    "        \n",
    "        # Collect text content\n",
    "        if frame_analysis.get('text_content'):\n",
    "            all_text_content.extend(frame_analysis['text_content'])\n",
    "        \n",
    "        # Create timeline entry\n",
    "        if frame_analysis.get('summary'):\n",
    "            activity_timeline.append(f\"**Frame {frame_num}** (Change: {diff_score:.3f}): {frame_analysis['summary'][:200]}...\")\n",
    "    \n",
    "    report.append(f\"This analysis covers {len(analyses)} significant frames extracted from the screen recording. \")\n",
    "    report.append(f\"The user was observed working with {len(all_applications)} different applications/tools. \")\n",
    "    report.append(\"The following report provides detailed insights into user activities and potential security considerations.\\n\\n\")\n",
    "    \n",
    "    # Applications used\n",
    "    report.append(\"## Applications and Tools Used\\n\\n\")\n",
    "    if all_applications:\n",
    "        for app in sorted(all_applications):\n",
    "            report.append(f\"- {app}\\n\")\n",
    "    else:\n",
    "        report.append(\"*No applications detected*\\n\")\n",
    "    report.append(\"\\n\")\n",
    "    \n",
    "    # Activity Timeline\n",
    "    report.append(\"## Activity Timeline\\n\\n\")\n",
    "    for activity in activity_timeline[:10]:  # Limit to first 10 for brevity\n",
    "        report.append(f\"{activity}\\n\\n\")\n",
    "    \n",
    "    if len(activity_timeline) > 10:\n",
    "        report.append(f\"*... and {len(activity_timeline) - 10} more activities*\\n\\n\")\n",
    "    \n",
    "    # Detailed Frame Analysis\n",
    "    report.append(\"## Detailed Frame Analysis\\n\\n\")\n",
    "    \n",
    "    for i, analysis in enumerate(analyses):\n",
    "        frame_num = analysis['frame_number']\n",
    "        diff_score = analysis['difference_score']\n",
    "        frame_analysis = analysis['analysis']\n",
    "        \n",
    "        report.append(f\"### Frame {frame_num} (Significance Score: {diff_score:.3f})\\n\\n\")\n",
    "        \n",
    "        # Applications in this frame\n",
    "        if frame_analysis.get('applications_open'):\n",
    "            report.append(\"**Applications:**\\n\")\n",
    "            for app in frame_analysis['applications_open']:\n",
    "                report.append(f\"- {app}\\n\")\n",
    "            report.append(\"\\n\")\n",
    "        \n",
    "        # Text content\n",
    "        if frame_analysis.get('text_content'):\n",
    "            report.append(\"**Visible Text Content:**\\n\")\n",
    "            report.append(\"```\\n\")\n",
    "            for text in frame_analysis['text_content'][:20]:  # Limit to first 20 items\n",
    "                report.append(f\"{text}\\n\")\n",
    "            if len(frame_analysis['text_content']) > 20:\n",
    "                report.append(f\"... and {len(frame_analysis['text_content']) - 20} more text elements\\n\")\n",
    "            report.append(\"```\\n\\n\")\n",
    "        \n",
    "        # Summary\n",
    "        if frame_analysis.get('summary'):\n",
    "            report.append(f\"**Analysis:** {frame_analysis['summary']}\\n\\n\")\n",
    "        \n",
    "        report.append(\"---\\n\\n\")\n",
    "    \n",
    "    # Security considerations\n",
    "    report.append(\"## Security and Compliance Notes\\n\\n\")\n",
    "    report.append(\"This analysis was performed for access management and security monitoring purposes. \")\n",
    "    report.append(\"Key observations:\\n\\n\")\n",
    "    report.append(f\"- Total significant activity changes detected: {len(analyses)}\\n\")\n",
    "    report.append(f\"- Applications accessed: {len(all_applications)}\\n\")\n",
    "    report.append(\"- All activities have been logged and analyzed for compliance\\n\")\n",
    "    report.append(\"- This report should be reviewed by authorized personnel only\\n\\n\")\n",
    "    \n",
    "    return ''.join(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "004a5946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛡️ ENHANCED VIDEO ANALYSIS WITH RATE LIMITING PROTECTION\n",
      "======================================================================\n",
      "📊 Enhanced Configuration:\n",
      "   difference_threshold: 0.1\n",
      "   min_frame_interval: 5\n",
      "   max_frames: 60\n",
      "   resize_factor: 1\n",
      "   max_retries: 5\n",
      "   sleep_duration: 70\n",
      "   cleanup_temp_files: False\n",
      "   username: AK_Test2\n",
      "\n",
      "⏱️  Estimated max processing time: 70.0 minutes\n",
      "   (if all frames hit rate limits)\n",
      "\n",
      "🚀 Starting enhanced video analysis...\n",
      "📹 Input: ./VidRecordings/CodingVBA_sample.mp4\n",
      "📄 Output: ./Outputs/analysis_output_coding_vba.md\n",
      "============================================================\n",
      "STARTING VIDEO ANALYSIS WITH FRAME DIFFERENCING\n",
      "============================================================\n",
      "\n",
      "1. Extracting significant frames from video...\n",
      "Video info: 52697 frames, 59.99 FPS\n",
      "Processing frames for significant changes...\n",
      "Progress: 0.2% (100/52697)\n",
      "Progress: 0.4% (200/52697)\n",
      "Progress: 0.6% (300/52697)\n",
      "Progress: 0.8% (400/52697)\n",
      "Progress: 0.9% (500/52697)\n",
      "Progress: 1.1% (600/52697)\n",
      "Progress: 1.3% (700/52697)\n",
      "Significant frame found: Frame 723, Change: 0.165\n",
      "Significant frame found: Frame 728, Change: 0.112\n",
      "Progress: 1.5% (800/52697)\n",
      "Progress: 1.7% (900/52697)\n",
      "Progress: 1.9% (1000/52697)\n",
      "Progress: 2.1% (1100/52697)\n",
      "Progress: 2.3% (1200/52697)\n",
      "Progress: 2.5% (1300/52697)\n",
      "Progress: 2.7% (1400/52697)\n",
      "Progress: 2.8% (1500/52697)\n",
      "Progress: 3.0% (1600/52697)\n",
      "Progress: 3.2% (1700/52697)\n",
      "Progress: 3.4% (1800/52697)\n",
      "Progress: 3.6% (1900/52697)\n",
      "Progress: 3.8% (2000/52697)\n",
      "Progress: 4.0% (2100/52697)\n",
      "Progress: 4.2% (2200/52697)\n",
      "Progress: 4.4% (2300/52697)\n",
      "Progress: 4.6% (2400/52697)\n",
      "Progress: 4.7% (2500/52697)\n",
      "Progress: 4.9% (2600/52697)\n",
      "Progress: 5.1% (2700/52697)\n",
      "Progress: 5.3% (2800/52697)\n",
      "Progress: 5.5% (2900/52697)\n",
      "Progress: 5.7% (3000/52697)\n",
      "Progress: 5.9% (3100/52697)\n",
      "Progress: 6.1% (3200/52697)\n",
      "Progress: 6.3% (3300/52697)\n",
      "Progress: 6.5% (3400/52697)\n",
      "Progress: 6.6% (3500/52697)\n",
      "Progress: 6.8% (3600/52697)\n",
      "Progress: 7.0% (3700/52697)\n",
      "Progress: 7.2% (3800/52697)\n",
      "Progress: 7.4% (3900/52697)\n",
      "Progress: 7.6% (4000/52697)\n",
      "Progress: 7.8% (4100/52697)\n",
      "Progress: 8.0% (4200/52697)\n",
      "Progress: 8.2% (4300/52697)\n",
      "Progress: 8.3% (4400/52697)\n",
      "Progress: 8.5% (4500/52697)\n",
      "Progress: 8.7% (4600/52697)\n",
      "Progress: 8.9% (4700/52697)\n",
      "Significant frame found: Frame 4777, Change: 0.772\n",
      "Progress: 9.1% (4800/52697)\n",
      "Significant frame found: Frame 4860, Change: 0.156\n",
      "Progress: 9.3% (4900/52697)\n",
      "Progress: 9.5% (5000/52697)\n",
      "Significant frame found: Frame 5025, Change: 0.127\n",
      "Progress: 9.7% (5100/52697)\n",
      "Significant frame found: Frame 5154, Change: 0.177\n",
      "Progress: 9.9% (5200/52697)\n",
      "Progress: 10.1% (5300/52697)\n",
      "Progress: 10.2% (5400/52697)\n",
      "Progress: 10.4% (5500/52697)\n",
      "Progress: 10.6% (5600/52697)\n",
      "Progress: 10.8% (5700/52697)\n",
      "Progress: 11.0% (5800/52697)\n",
      "Progress: 11.2% (5900/52697)\n",
      "Progress: 11.4% (6000/52697)\n",
      "Progress: 11.6% (6100/52697)\n",
      "Progress: 11.8% (6200/52697)\n",
      "Progress: 12.0% (6300/52697)\n",
      "Progress: 12.1% (6400/52697)\n",
      "Progress: 12.3% (6500/52697)\n",
      "Progress: 12.5% (6600/52697)\n",
      "Progress: 12.7% (6700/52697)\n",
      "Progress: 12.9% (6800/52697)\n",
      "Progress: 13.1% (6900/52697)\n",
      "Progress: 13.3% (7000/52697)\n",
      "Progress: 13.5% (7100/52697)\n",
      "Progress: 13.7% (7200/52697)\n",
      "Progress: 13.9% (7300/52697)\n",
      "Progress: 14.0% (7400/52697)\n",
      "Progress: 14.2% (7500/52697)\n",
      "Progress: 14.4% (7600/52697)\n",
      "Progress: 14.6% (7700/52697)\n",
      "Progress: 14.8% (7800/52697)\n",
      "Progress: 15.0% (7900/52697)\n",
      "Progress: 15.2% (8000/52697)\n",
      "Progress: 15.4% (8100/52697)\n",
      "Progress: 15.6% (8200/52697)\n",
      "Progress: 15.8% (8300/52697)\n",
      "Progress: 15.9% (8400/52697)\n",
      "Progress: 16.1% (8500/52697)\n",
      "Significant frame found: Frame 8581, Change: 0.140\n",
      "Progress: 16.3% (8600/52697)\n",
      "Progress: 16.5% (8700/52697)\n",
      "Significant frame found: Frame 8706, Change: 0.248\n",
      "Progress: 16.7% (8800/52697)\n",
      "Progress: 16.9% (8900/52697)\n",
      "Progress: 17.1% (9000/52697)\n",
      "Progress: 17.3% (9100/52697)\n",
      "Progress: 17.5% (9200/52697)\n",
      "Progress: 17.6% (9300/52697)\n",
      "Progress: 17.8% (9400/52697)\n",
      "Progress: 18.0% (9500/52697)\n",
      "Progress: 18.2% (9600/52697)\n",
      "Progress: 18.4% (9700/52697)\n",
      "Significant frame found: Frame 9797, Change: 0.102\n",
      "Progress: 18.6% (9800/52697)\n",
      "Progress: 18.8% (9900/52697)\n",
      "Progress: 19.0% (10000/52697)\n",
      "Progress: 19.2% (10100/52697)\n",
      "Progress: 19.4% (10200/52697)\n",
      "Progress: 19.5% (10300/52697)\n",
      "Significant frame found: Frame 10307, Change: 0.105\n",
      "Progress: 19.7% (10400/52697)\n",
      "Progress: 19.9% (10500/52697)\n",
      "Progress: 20.1% (10600/52697)\n",
      "Progress: 20.3% (10700/52697)\n",
      "Progress: 20.5% (10800/52697)\n",
      "Progress: 20.7% (10900/52697)\n",
      "Progress: 20.9% (11000/52697)\n",
      "Progress: 21.1% (11100/52697)\n",
      "Progress: 21.3% (11200/52697)\n",
      "Progress: 21.4% (11300/52697)\n",
      "Progress: 21.6% (11400/52697)\n",
      "Progress: 21.8% (11500/52697)\n",
      "Progress: 22.0% (11600/52697)\n",
      "Progress: 22.2% (11700/52697)\n",
      "Progress: 22.4% (11800/52697)\n",
      "Progress: 22.6% (11900/52697)\n",
      "Progress: 22.8% (12000/52697)\n",
      "Progress: 23.0% (12100/52697)\n",
      "Progress: 23.2% (12200/52697)\n",
      "Progress: 23.3% (12300/52697)\n",
      "Progress: 23.5% (12400/52697)\n",
      "Progress: 23.7% (12500/52697)\n",
      "Progress: 23.9% (12600/52697)\n",
      "Progress: 24.1% (12700/52697)\n",
      "Progress: 24.3% (12800/52697)\n",
      "Progress: 24.5% (12900/52697)\n",
      "Progress: 24.7% (13000/52697)\n",
      "Progress: 24.9% (13100/52697)\n",
      "Significant frame found: Frame 13111, Change: 0.143\n",
      "Progress: 25.0% (13200/52697)\n",
      "Progress: 25.2% (13300/52697)\n",
      "Progress: 25.4% (13400/52697)\n",
      "Progress: 25.6% (13500/52697)\n",
      "Progress: 25.8% (13600/52697)\n",
      "Progress: 26.0% (13700/52697)\n",
      "Progress: 26.2% (13800/52697)\n",
      "Progress: 26.4% (13900/52697)\n",
      "Progress: 26.6% (14000/52697)\n",
      "Progress: 26.8% (14100/52697)\n",
      "Progress: 26.9% (14200/52697)\n",
      "Progress: 27.1% (14300/52697)\n",
      "Progress: 27.3% (14400/52697)\n",
      "Progress: 27.5% (14500/52697)\n",
      "Progress: 27.7% (14600/52697)\n",
      "Significant frame found: Frame 14647, Change: 0.157\n",
      "Progress: 27.9% (14700/52697)\n",
      "Progress: 28.1% (14800/52697)\n",
      "Progress: 28.3% (14900/52697)\n",
      "Progress: 28.5% (15000/52697)\n",
      "Progress: 28.7% (15100/52697)\n",
      "Significant frame found: Frame 15147, Change: 0.232\n",
      "Progress: 28.8% (15200/52697)\n",
      "Progress: 29.0% (15300/52697)\n",
      "Progress: 29.2% (15400/52697)\n",
      "Progress: 29.4% (15500/52697)\n",
      "Progress: 29.6% (15600/52697)\n",
      "Significant frame found: Frame 15659, Change: 0.204\n",
      "Progress: 29.8% (15700/52697)\n",
      "Progress: 30.0% (15800/52697)\n",
      "Significant frame found: Frame 15824, Change: 0.249\n",
      "Progress: 30.2% (15900/52697)\n",
      "Progress: 30.4% (16000/52697)\n",
      "Progress: 30.6% (16100/52697)\n",
      "Progress: 30.7% (16200/52697)\n",
      "Significant frame found: Frame 16259, Change: 0.135\n",
      "Progress: 30.9% (16300/52697)\n",
      "Progress: 31.1% (16400/52697)\n",
      "Progress: 31.3% (16500/52697)\n",
      "Progress: 31.5% (16600/52697)\n",
      "Progress: 31.7% (16700/52697)\n",
      "Progress: 31.9% (16800/52697)\n",
      "Progress: 32.1% (16900/52697)\n",
      "Progress: 32.3% (17000/52697)\n",
      "Progress: 32.4% (17100/52697)\n",
      "Progress: 32.6% (17200/52697)\n",
      "Progress: 32.8% (17300/52697)\n",
      "Progress: 33.0% (17400/52697)\n",
      "Progress: 33.2% (17500/52697)\n",
      "Progress: 33.4% (17600/52697)\n",
      "Progress: 33.6% (17700/52697)\n",
      "Progress: 33.8% (17800/52697)\n",
      "Progress: 34.0% (17900/52697)\n",
      "Progress: 34.2% (18000/52697)\n",
      "Progress: 34.3% (18100/52697)\n",
      "Progress: 34.5% (18200/52697)\n",
      "Progress: 34.7% (18300/52697)\n",
      "Progress: 34.9% (18400/52697)\n",
      "Progress: 35.1% (18500/52697)\n",
      "Progress: 35.3% (18600/52697)\n",
      "Progress: 35.5% (18700/52697)\n",
      "Progress: 35.7% (18800/52697)\n",
      "Progress: 35.9% (18900/52697)\n",
      "Progress: 36.1% (19000/52697)\n",
      "Progress: 36.2% (19100/52697)\n",
      "Progress: 36.4% (19200/52697)\n",
      "Progress: 36.6% (19300/52697)\n",
      "Progress: 36.8% (19400/52697)\n",
      "Progress: 37.0% (19500/52697)\n",
      "Progress: 37.2% (19600/52697)\n",
      "Progress: 37.4% (19700/52697)\n",
      "Progress: 37.6% (19800/52697)\n",
      "Progress: 37.8% (19900/52697)\n",
      "Progress: 38.0% (20000/52697)\n",
      "Progress: 38.1% (20100/52697)\n",
      "Progress: 38.3% (20200/52697)\n",
      "Progress: 38.5% (20300/52697)\n",
      "Progress: 38.7% (20400/52697)\n",
      "Progress: 38.9% (20500/52697)\n",
      "Progress: 39.1% (20600/52697)\n",
      "Progress: 39.3% (20700/52697)\n",
      "Progress: 39.5% (20800/52697)\n",
      "Progress: 39.7% (20900/52697)\n",
      "Progress: 39.9% (21000/52697)\n",
      "Progress: 40.0% (21100/52697)\n",
      "Progress: 40.2% (21200/52697)\n",
      "Progress: 40.4% (21300/52697)\n",
      "Progress: 40.6% (21400/52697)\n",
      "Progress: 40.8% (21500/52697)\n",
      "Progress: 41.0% (21600/52697)\n",
      "Progress: 41.2% (21700/52697)\n",
      "Progress: 41.4% (21800/52697)\n",
      "Progress: 41.6% (21900/52697)\n",
      "Progress: 41.7% (22000/52697)\n",
      "Progress: 41.9% (22100/52697)\n",
      "Progress: 42.1% (22200/52697)\n",
      "Progress: 42.3% (22300/52697)\n",
      "Progress: 42.5% (22400/52697)\n",
      "Progress: 42.7% (22500/52697)\n",
      "Progress: 42.9% (22600/52697)\n",
      "Progress: 43.1% (22700/52697)\n",
      "Progress: 43.3% (22800/52697)\n",
      "Progress: 43.5% (22900/52697)\n",
      "Progress: 43.6% (23000/52697)\n",
      "Progress: 43.8% (23100/52697)\n",
      "Progress: 44.0% (23200/52697)\n",
      "Progress: 44.2% (23300/52697)\n",
      "Progress: 44.4% (23400/52697)\n",
      "Progress: 44.6% (23500/52697)\n",
      "Progress: 44.8% (23600/52697)\n",
      "Progress: 45.0% (23700/52697)\n",
      "Progress: 45.2% (23800/52697)\n",
      "Progress: 45.4% (23900/52697)\n",
      "Progress: 45.5% (24000/52697)\n",
      "Progress: 45.7% (24100/52697)\n",
      "Progress: 45.9% (24200/52697)\n",
      "Progress: 46.1% (24300/52697)\n",
      "Progress: 46.3% (24400/52697)\n",
      "Significant frame found: Frame 24440, Change: 0.119\n",
      "Significant frame found: Frame 24445, Change: 0.143\n",
      "Significant frame found: Frame 24491, Change: 0.102\n",
      "Progress: 46.5% (24500/52697)\n",
      "Progress: 46.7% (24600/52697)\n",
      "Progress: 46.9% (24700/52697)\n",
      "Progress: 47.1% (24800/52697)\n",
      "Progress: 47.3% (24900/52697)\n",
      "Progress: 47.4% (25000/52697)\n",
      "Progress: 47.6% (25100/52697)\n",
      "Progress: 47.8% (25200/52697)\n",
      "Progress: 48.0% (25300/52697)\n",
      "Progress: 48.2% (25400/52697)\n",
      "Progress: 48.4% (25500/52697)\n",
      "Progress: 48.6% (25600/52697)\n",
      "Progress: 48.8% (25700/52697)\n",
      "Progress: 49.0% (25800/52697)\n",
      "Progress: 49.1% (25900/52697)\n",
      "Progress: 49.3% (26000/52697)\n",
      "Progress: 49.5% (26100/52697)\n",
      "Progress: 49.7% (26200/52697)\n",
      "Progress: 49.9% (26300/52697)\n",
      "Progress: 50.1% (26400/52697)\n",
      "Progress: 50.3% (26500/52697)\n",
      "Progress: 50.5% (26600/52697)\n",
      "Progress: 50.7% (26700/52697)\n",
      "Progress: 50.9% (26800/52697)\n",
      "Significant frame found: Frame 26841, Change: 0.248\n",
      "Progress: 51.0% (26900/52697)\n",
      "Progress: 51.2% (27000/52697)\n",
      "Progress: 51.4% (27100/52697)\n",
      "Progress: 51.6% (27200/52697)\n",
      "Significant frame found: Frame 27211, Change: 0.121\n",
      "Significant frame found: Frame 27216, Change: 0.133\n",
      "Progress: 51.8% (27300/52697)\n",
      "Progress: 52.0% (27400/52697)\n",
      "Progress: 52.2% (27500/52697)\n",
      "Progress: 52.4% (27600/52697)\n",
      "Progress: 52.6% (27700/52697)\n",
      "Progress: 52.8% (27800/52697)\n",
      "Progress: 52.9% (27900/52697)\n",
      "Progress: 53.1% (28000/52697)\n",
      "Progress: 53.3% (28100/52697)\n",
      "Progress: 53.5% (28200/52697)\n",
      "Progress: 53.7% (28300/52697)\n",
      "Progress: 53.9% (28400/52697)\n",
      "Progress: 54.1% (28500/52697)\n",
      "Progress: 54.3% (28600/52697)\n",
      "Progress: 54.5% (28700/52697)\n",
      "Progress: 54.7% (28800/52697)\n",
      "Progress: 54.8% (28900/52697)\n",
      "Progress: 55.0% (29000/52697)\n",
      "Progress: 55.2% (29100/52697)\n",
      "Progress: 55.4% (29200/52697)\n",
      "Progress: 55.6% (29300/52697)\n",
      "Progress: 55.8% (29400/52697)\n",
      "Progress: 56.0% (29500/52697)\n",
      "Progress: 56.2% (29600/52697)\n",
      "Progress: 56.4% (29700/52697)\n",
      "Progress: 56.5% (29800/52697)\n",
      "Progress: 56.7% (29900/52697)\n",
      "Progress: 56.9% (30000/52697)\n",
      "Progress: 57.1% (30100/52697)\n",
      "Progress: 57.3% (30200/52697)\n",
      "Progress: 57.5% (30300/52697)\n",
      "Progress: 57.7% (30400/52697)\n",
      "Progress: 57.9% (30500/52697)\n",
      "Progress: 58.1% (30600/52697)\n",
      "Progress: 58.3% (30700/52697)\n",
      "Progress: 58.4% (30800/52697)\n",
      "Progress: 58.6% (30900/52697)\n",
      "Progress: 58.8% (31000/52697)\n",
      "Progress: 59.0% (31100/52697)\n",
      "Progress: 59.2% (31200/52697)\n",
      "Progress: 59.4% (31300/52697)\n",
      "Progress: 59.6% (31400/52697)\n",
      "Progress: 59.8% (31500/52697)\n",
      "Progress: 60.0% (31600/52697)\n",
      "Progress: 60.2% (31700/52697)\n",
      "Progress: 60.3% (31800/52697)\n",
      "Progress: 60.5% (31900/52697)\n",
      "Progress: 60.7% (32000/52697)\n",
      "Progress: 60.9% (32100/52697)\n",
      "Progress: 61.1% (32200/52697)\n",
      "Progress: 61.3% (32300/52697)\n",
      "Progress: 61.5% (32400/52697)\n",
      "Progress: 61.7% (32500/52697)\n",
      "Progress: 61.9% (32600/52697)\n",
      "Progress: 62.1% (32700/52697)\n",
      "Progress: 62.2% (32800/52697)\n",
      "Progress: 62.4% (32900/52697)\n",
      "Progress: 62.6% (33000/52697)\n",
      "Progress: 62.8% (33100/52697)\n",
      "Progress: 63.0% (33200/52697)\n",
      "Progress: 63.2% (33300/52697)\n",
      "Progress: 63.4% (33400/52697)\n",
      "Progress: 63.6% (33500/52697)\n",
      "Significant frame found: Frame 33507, Change: 0.233\n",
      "Significant frame found: Frame 33555, Change: 0.101\n",
      "Progress: 63.8% (33600/52697)\n",
      "Progress: 64.0% (33700/52697)\n",
      "Progress: 64.1% (33800/52697)\n",
      "Progress: 64.3% (33900/52697)\n",
      "Progress: 64.5% (34000/52697)\n",
      "Progress: 64.7% (34100/52697)\n",
      "Progress: 64.9% (34200/52697)\n",
      "Progress: 65.1% (34300/52697)\n",
      "Progress: 65.3% (34400/52697)\n",
      "Progress: 65.5% (34500/52697)\n",
      "Progress: 65.7% (34600/52697)\n",
      "Progress: 65.8% (34700/52697)\n",
      "Progress: 66.0% (34800/52697)\n",
      "Progress: 66.2% (34900/52697)\n",
      "Progress: 66.4% (35000/52697)\n",
      "Progress: 66.6% (35100/52697)\n",
      "Progress: 66.8% (35200/52697)\n",
      "Progress: 67.0% (35300/52697)\n",
      "Significant frame found: Frame 35361, Change: 0.259\n",
      "Progress: 67.2% (35400/52697)\n",
      "Significant frame found: Frame 35434, Change: 0.108\n",
      "Progress: 67.4% (35500/52697)\n",
      "Progress: 67.6% (35600/52697)\n",
      "Progress: 67.7% (35700/52697)\n",
      "Progress: 67.9% (35800/52697)\n",
      "Progress: 68.1% (35900/52697)\n",
      "Progress: 68.3% (36000/52697)\n",
      "Progress: 68.5% (36100/52697)\n",
      "Progress: 68.7% (36200/52697)\n",
      "Progress: 68.9% (36300/52697)\n",
      "Progress: 69.1% (36400/52697)\n",
      "Progress: 69.3% (36500/52697)\n",
      "Progress: 69.5% (36600/52697)\n",
      "Progress: 69.6% (36700/52697)\n",
      "Progress: 69.8% (36800/52697)\n",
      "Progress: 70.0% (36900/52697)\n",
      "Progress: 70.2% (37000/52697)\n",
      "Progress: 70.4% (37100/52697)\n",
      "Progress: 70.6% (37200/52697)\n",
      "Progress: 70.8% (37300/52697)\n",
      "Progress: 71.0% (37400/52697)\n",
      "Progress: 71.2% (37500/52697)\n",
      "Progress: 71.4% (37600/52697)\n",
      "Progress: 71.5% (37700/52697)\n",
      "Progress: 71.7% (37800/52697)\n",
      "Progress: 71.9% (37900/52697)\n",
      "Significant frame found: Frame 37932, Change: 0.246\n",
      "Significant frame found: Frame 37999, Change: 0.118\n",
      "Progress: 72.1% (38000/52697)\n",
      "Progress: 72.3% (38100/52697)\n",
      "Progress: 72.5% (38200/52697)\n",
      "Progress: 72.7% (38300/52697)\n",
      "Progress: 72.9% (38400/52697)\n",
      "Progress: 73.1% (38500/52697)\n",
      "Significant frame found: Frame 38569, Change: 0.247\n",
      "Progress: 73.2% (38600/52697)\n",
      "Significant frame found: Frame 38645, Change: 0.118\n",
      "Progress: 73.4% (38700/52697)\n",
      "Progress: 73.6% (38800/52697)\n",
      "Significant frame found: Frame 38893, Change: 0.116\n",
      "Significant frame found: Frame 38898, Change: 0.160\n",
      "Progress: 73.8% (38900/52697)\n",
      "Significant frame found: Frame 38917, Change: 0.131\n",
      "Significant frame found: Frame 38929, Change: 0.102\n",
      "Progress: 74.0% (39000/52697)\n",
      "Progress: 74.2% (39100/52697)\n",
      "Progress: 74.4% (39200/52697)\n",
      "Progress: 74.6% (39300/52697)\n",
      "Progress: 74.8% (39400/52697)\n",
      "Progress: 75.0% (39500/52697)\n",
      "Progress: 75.1% (39600/52697)\n",
      "Progress: 75.3% (39700/52697)\n",
      "Progress: 75.5% (39800/52697)\n",
      "Progress: 75.7% (39900/52697)\n",
      "Progress: 75.9% (40000/52697)\n",
      "Progress: 76.1% (40100/52697)\n",
      "Progress: 76.3% (40200/52697)\n",
      "Progress: 76.5% (40300/52697)\n",
      "Progress: 76.7% (40400/52697)\n",
      "Progress: 76.9% (40500/52697)\n",
      "Progress: 77.0% (40600/52697)\n",
      "Progress: 77.2% (40700/52697)\n",
      "Progress: 77.4% (40800/52697)\n",
      "Significant frame found: Frame 40822, Change: 0.284\n",
      "Progress: 77.6% (40900/52697)\n",
      "Progress: 77.8% (41000/52697)\n",
      "Progress: 78.0% (41100/52697)\n",
      "Progress: 78.2% (41200/52697)\n",
      "Progress: 78.4% (41300/52697)\n",
      "Progress: 78.6% (41400/52697)\n",
      "Progress: 78.8% (41500/52697)\n",
      "Progress: 78.9% (41600/52697)\n",
      "Progress: 79.1% (41700/52697)\n",
      "Progress: 79.3% (41800/52697)\n",
      "Significant frame found: Frame 41815, Change: 0.114\n",
      "Progress: 79.5% (41900/52697)\n",
      "Progress: 79.7% (42000/52697)\n",
      "Progress: 79.9% (42100/52697)\n",
      "Progress: 80.1% (42200/52697)\n",
      "Progress: 80.3% (42300/52697)\n",
      "Progress: 80.5% (42400/52697)\n",
      "Progress: 80.6% (42500/52697)\n",
      "Progress: 80.8% (42600/52697)\n",
      "Progress: 81.0% (42700/52697)\n",
      "Progress: 81.2% (42800/52697)\n",
      "Progress: 81.4% (42900/52697)\n",
      "Progress: 81.6% (43000/52697)\n",
      "Progress: 81.8% (43100/52697)\n",
      "Progress: 82.0% (43200/52697)\n",
      "Progress: 82.2% (43300/52697)\n",
      "Progress: 82.4% (43400/52697)\n",
      "Progress: 82.5% (43500/52697)\n",
      "Progress: 82.7% (43600/52697)\n",
      "Progress: 82.9% (43700/52697)\n",
      "Progress: 83.1% (43800/52697)\n",
      "Progress: 83.3% (43900/52697)\n",
      "Progress: 83.5% (44000/52697)\n",
      "Progress: 83.7% (44100/52697)\n",
      "Progress: 83.9% (44200/52697)\n",
      "Progress: 84.1% (44300/52697)\n",
      "Progress: 84.3% (44400/52697)\n",
      "Progress: 84.4% (44500/52697)\n",
      "Progress: 84.6% (44600/52697)\n",
      "Progress: 84.8% (44700/52697)\n",
      "Progress: 85.0% (44800/52697)\n",
      "Progress: 85.2% (44900/52697)\n",
      "Progress: 85.4% (45000/52697)\n",
      "Progress: 85.6% (45100/52697)\n",
      "Progress: 85.8% (45200/52697)\n",
      "Progress: 86.0% (45300/52697)\n",
      "Progress: 86.2% (45400/52697)\n",
      "Progress: 86.3% (45500/52697)\n",
      "Progress: 86.5% (45600/52697)\n",
      "Progress: 86.7% (45700/52697)\n",
      "Progress: 86.9% (45800/52697)\n",
      "Progress: 87.1% (45900/52697)\n",
      "Progress: 87.3% (46000/52697)\n",
      "Progress: 87.5% (46100/52697)\n",
      "Progress: 87.7% (46200/52697)\n",
      "Progress: 87.9% (46300/52697)\n",
      "Progress: 88.1% (46400/52697)\n",
      "Progress: 88.2% (46500/52697)\n",
      "Progress: 88.4% (46600/52697)\n",
      "Progress: 88.6% (46700/52697)\n",
      "Progress: 88.8% (46800/52697)\n",
      "Progress: 89.0% (46900/52697)\n",
      "Progress: 89.2% (47000/52697)\n",
      "Progress: 89.4% (47100/52697)\n",
      "Progress: 89.6% (47200/52697)\n",
      "Progress: 89.8% (47300/52697)\n",
      "Progress: 89.9% (47400/52697)\n",
      "Progress: 90.1% (47500/52697)\n",
      "Progress: 90.3% (47600/52697)\n",
      "Progress: 90.5% (47700/52697)\n",
      "Progress: 90.7% (47800/52697)\n",
      "Progress: 90.9% (47900/52697)\n",
      "Progress: 91.1% (48000/52697)\n",
      "Progress: 91.3% (48100/52697)\n",
      "Progress: 91.5% (48200/52697)\n",
      "Progress: 91.7% (48300/52697)\n",
      "Progress: 91.8% (48400/52697)\n",
      "Progress: 92.0% (48500/52697)\n",
      "Progress: 92.2% (48600/52697)\n",
      "Progress: 92.4% (48700/52697)\n",
      "Progress: 92.6% (48800/52697)\n",
      "Progress: 92.8% (48900/52697)\n",
      "Progress: 93.0% (49000/52697)\n",
      "Progress: 93.2% (49100/52697)\n",
      "Progress: 93.4% (49200/52697)\n",
      "Progress: 93.6% (49300/52697)\n",
      "Progress: 93.7% (49400/52697)\n",
      "Progress: 93.9% (49500/52697)\n",
      "Progress: 94.1% (49600/52697)\n",
      "Progress: 94.3% (49700/52697)\n",
      "Progress: 94.5% (49800/52697)\n",
      "Progress: 94.7% (49900/52697)\n",
      "Progress: 94.9% (50000/52697)\n",
      "Progress: 95.1% (50100/52697)\n",
      "Progress: 95.3% (50200/52697)\n",
      "Progress: 95.5% (50300/52697)\n",
      "Progress: 95.6% (50400/52697)\n",
      "Progress: 95.8% (50500/52697)\n",
      "Progress: 96.0% (50600/52697)\n",
      "Progress: 96.2% (50700/52697)\n",
      "Progress: 96.4% (50800/52697)\n",
      "Progress: 96.6% (50900/52697)\n",
      "Progress: 96.8% (51000/52697)\n",
      "Progress: 97.0% (51100/52697)\n",
      "Progress: 97.2% (51200/52697)\n",
      "Progress: 97.3% (51300/52697)\n",
      "Progress: 97.5% (51400/52697)\n",
      "Significant frame found: Frame 51410, Change: 0.276\n",
      "Significant frame found: Frame 51486, Change: 0.108\n",
      "Progress: 97.7% (51500/52697)\n",
      "Progress: 97.9% (51600/52697)\n",
      "Progress: 98.1% (51700/52697)\n",
      "Progress: 98.3% (51800/52697)\n",
      "Progress: 98.5% (51900/52697)\n",
      "Significant frame found: Frame 51968, Change: 0.287\n",
      "Progress: 98.7% (52000/52697)\n",
      "Progress: 98.9% (52100/52697)\n",
      "Progress: 99.1% (52200/52697)\n",
      "Progress: 99.2% (52300/52697)\n",
      "Progress: 99.4% (52400/52697)\n",
      "Progress: 99.6% (52500/52697)\n",
      "Significant frame found: Frame 52595, Change: 0.263\n",
      "Progress: 99.8% (52600/52697)\n",
      "Significant frame found: Frame 52696, Change: 0.265\n",
      "Extracted 42 significant frames from 52697 total frames\n",
      "Frame reduction: 99.9%\n",
      "\n",
      "2. Saving frames as temporary images...\n",
      "Saved 42 frame images to ./temp_frames\n",
      "\n",
      "3. Analyzing frames with Llama4 Maverick...\n",
      "   Rate limiting protection: 5 retries, 70s sleep\n",
      "\n",
      "📸 Analyzing frame 1/42: frame_000000_diff_1.000.png\n",
      "  ✅ Frame 0 analyzed successfully (diff: 1.000)\n",
      "\n",
      "📸 Analyzing frame 2/42: frame_000723_diff_0.165.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 723 analyzed successfully (diff: 0.165)\n",
      "\n",
      "📸 Analyzing frame 3/42: frame_000728_diff_0.112.png\n",
      "  ✅ Frame 728 analyzed successfully (diff: 0.112)\n",
      "\n",
      "📸 Analyzing frame 4/42: frame_004777_diff_0.772.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 4777 analyzed successfully (diff: 0.772)\n",
      "\n",
      "📸 Analyzing frame 5/42: frame_004860_diff_0.156.png\n",
      "  ✅ Frame 4860 analyzed successfully (diff: 0.156)\n",
      "\n",
      "📸 Analyzing frame 6/42: frame_005025_diff_0.127.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 5025 analyzed successfully (diff: 0.127)\n",
      "\n",
      "📸 Analyzing frame 7/42: frame_005154_diff_0.177.png\n",
      "  ✅ Frame 5154 analyzed successfully (diff: 0.177)\n",
      "\n",
      "📸 Analyzing frame 8/42: frame_008581_diff_0.140.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 8581 analyzed successfully (diff: 0.140)\n",
      "\n",
      "📸 Analyzing frame 9/42: frame_008706_diff_0.248.png\n",
      "  ✅ Frame 8706 analyzed successfully (diff: 0.248)\n",
      "\n",
      "📸 Analyzing frame 10/42: frame_009797_diff_0.102.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 9797 analyzed successfully (diff: 0.102)\n",
      "\n",
      "📸 Analyzing frame 11/42: frame_010307_diff_0.105.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 10307 analyzed successfully (diff: 0.105)\n",
      "\n",
      "📸 Analyzing frame 12/42: frame_013111_diff_0.143.png\n",
      "  ✅ Frame 13111 analyzed successfully (diff: 0.143)\n",
      "\n",
      "📸 Analyzing frame 13/42: frame_014647_diff_0.157.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 14647 analyzed successfully (diff: 0.157)\n",
      "\n",
      "📸 Analyzing frame 14/42: frame_015147_diff_0.232.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 15147 analyzed successfully (diff: 0.232)\n",
      "\n",
      "📸 Analyzing frame 15/42: frame_015659_diff_0.204.png\n",
      "  ✅ Frame 15659 analyzed successfully (diff: 0.204)\n",
      "\n",
      "📸 Analyzing frame 16/42: frame_015824_diff_0.249.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 15824 analyzed successfully (diff: 0.249)\n",
      "\n",
      "📸 Analyzing frame 17/42: frame_016259_diff_0.135.png\n",
      "  ✅ Frame 16259 analyzed successfully (diff: 0.135)\n",
      "\n",
      "📸 Analyzing frame 18/42: frame_024440_diff_0.119.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 24440 analyzed successfully (diff: 0.119)\n",
      "\n",
      "📸 Analyzing frame 19/42: frame_024445_diff_0.143.png\n",
      "  ✅ Frame 24445 analyzed successfully (diff: 0.143)\n",
      "\n",
      "📸 Analyzing frame 20/42: frame_024491_diff_0.102.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 24491 analyzed successfully (diff: 0.102)\n",
      "\n",
      "📸 Analyzing frame 21/42: frame_026841_diff_0.248.png\n",
      "  ✅ Frame 26841 analyzed successfully (diff: 0.248)\n",
      "\n",
      "📸 Analyzing frame 22/42: frame_027211_diff_0.121.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 27211 analyzed successfully (diff: 0.121)\n",
      "\n",
      "📸 Analyzing frame 23/42: frame_027216_diff_0.133.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 27216 analyzed successfully (diff: 0.133)\n",
      "\n",
      "📸 Analyzing frame 24/42: frame_033507_diff_0.233.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 33507 analyzed successfully (diff: 0.233)\n",
      "\n",
      "📸 Analyzing frame 25/42: frame_033555_diff_0.101.png\n",
      "  ✅ Frame 33555 analyzed successfully (diff: 0.101)\n",
      "\n",
      "📸 Analyzing frame 26/42: frame_035361_diff_0.259.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 35361 analyzed successfully (diff: 0.259)\n",
      "\n",
      "📸 Analyzing frame 27/42: frame_035434_diff_0.108.png\n",
      "  ✅ Frame 35434 analyzed successfully (diff: 0.108)\n",
      "\n",
      "📸 Analyzing frame 28/42: frame_037932_diff_0.246.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 37932 analyzed successfully (diff: 0.246)\n",
      "\n",
      "📸 Analyzing frame 29/42: frame_037999_diff_0.118.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 37999 analyzed successfully (diff: 0.118)\n",
      "\n",
      "📸 Analyzing frame 30/42: frame_038569_diff_0.247.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 38569 analyzed successfully (diff: 0.247)\n",
      "\n",
      "📸 Analyzing frame 31/42: frame_038645_diff_0.118.png\n",
      "  ✅ Frame 38645 analyzed successfully (diff: 0.118)\n",
      "\n",
      "📸 Analyzing frame 32/42: frame_038893_diff_0.116.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 38893 analyzed successfully (diff: 0.116)\n",
      "\n",
      "📸 Analyzing frame 33/42: frame_038898_diff_0.160.png\n",
      "  ✅ Frame 38898 analyzed successfully (diff: 0.160)\n",
      "\n",
      "📸 Analyzing frame 34/42: frame_038917_diff_0.131.png\n",
      "  ✅ Frame 38917 analyzed successfully (diff: 0.131)\n",
      "\n",
      "📸 Analyzing frame 35/42: frame_038929_diff_0.102.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 38929 analyzed successfully (diff: 0.102)\n",
      "\n",
      "📸 Analyzing frame 36/42: frame_040822_diff_0.284.png\n",
      "  ✅ Frame 40822 analyzed successfully (diff: 0.284)\n",
      "\n",
      "📸 Analyzing frame 37/42: frame_041815_diff_0.114.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 41815 analyzed successfully (diff: 0.114)\n",
      "\n",
      "📸 Analyzing frame 38/42: frame_051410_diff_0.276.png\n",
      "  ✅ Frame 51410 analyzed successfully (diff: 0.276)\n",
      "\n",
      "📸 Analyzing frame 39/42: frame_051486_diff_0.108.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 51486 analyzed successfully (diff: 0.108)\n",
      "\n",
      "📸 Analyzing frame 40/42: frame_051968_diff_0.287.png\n",
      "  ✅ Frame 51968 analyzed successfully (diff: 0.287)\n",
      "\n",
      "📸 Analyzing frame 41/42: frame_052595_diff_0.263.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 52595 analyzed successfully (diff: 0.263)\n",
      "\n",
      "📸 Analyzing frame 42/42: frame_052696_diff_0.265.png\n",
      "    ⏳ Rate limit hit (attempt 1/6). Sleeping for 70 seconds...\n",
      "    🔄 Retrying frame analysis...\n",
      "  ✅ Frame 52696 analyzed successfully (diff: 0.265)\n",
      "\n",
      "4. Generating comprehensive analysis report...\n",
      "\n",
      "✓ Analysis complete! Report saved to: ./Outputs/analysis_output_coding_vba.md\n",
      "\n",
      "============================================================\n",
      "VIDEO ANALYSIS COMPLETED SUCCESSFULLY\n",
      "============================================================\n",
      "\n",
      "🎉 SUCCESS! Enhanced video analysis completed.\n",
      "📄 Report saved to: ./Outputs/analysis_output_coding_vba.md\n",
      "💰 Cost optimization: Only 60 frames analyzed\n",
      "🛡️ Rate limiting protection: 5 retries, 70s sleep\n",
      "\n",
      "======================================================================\n",
      "💡 RATE LIMITING TIPS:\n",
      "======================================================================\n",
      "• Current API limit: 0.6 queries/minute (1 query every ~100 seconds)\n",
      "• Sleep duration: 70s provides buffer for rate limiting\n",
      "• Max retries: 5 attempts per frame\n",
      "• Frames reduced to 60 for faster completion\n",
      "• Processing will automatically retry failed frames after rate limit cooldown\n",
      "• Monitor console output for retry status and progress\n"
     ]
    }
   ],
   "source": [
    "# UPDATED EXECUTION WITH RATE LIMITING PROTECTION\n",
    "# Use this cell instead of the previous one for better rate limiting handling\n",
    "\n",
    "# Enhanced configuration with rate limiting protection\n",
    "ENHANCED_CONFIG = {\n",
    "    # Frame Extraction Settings\n",
    "    'difference_threshold': 0.1,    # Lower = more sensitive to changes (0.05-0.3 recommended)\n",
    "    'min_frame_interval': 5,        # Minimum frames between captures (reduces redundancy)\n",
    "    'max_frames': 60,                # Maximum frames to analyze (reduced for rate limiting)\n",
    "    'resize_factor': 1,            # Resize frames for faster processing (0.3-1.0)\n",
    "    \n",
    "    # Rate Limiting Protection Settings - NEW!\n",
    "    'max_retries': 5,                # Number of retry attempts for rate limited requests\n",
    "    'sleep_duration': 70,            # Sleep duration in seconds when rate limited (70+ recommended)\n",
    "    \n",
    "    # General Settings\n",
    "    'cleanup_temp_files': False,      # Clean up temporary frame files after processing\n",
    "    'username': 'AK_Test2'   # Username for the report\n",
    "}\n",
    "\n",
    "print(\"🛡️ ENHANCED VIDEO ANALYSIS WITH RATE LIMITING PROTECTION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"📊 Enhanced Configuration:\")\n",
    "for key, value in ENHANCED_CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(f\"\\n⏱️  Estimated max processing time: {ENHANCED_CONFIG['max_frames'] * ENHANCED_CONFIG['sleep_duration'] / 60:.1f} minutes\")\n",
    "print(f\"   (if all frames hit rate limits)\")\n",
    "\n",
    "try:\n",
    "    print(f\"\\n🚀 Starting enhanced video analysis...\")\n",
    "    print(f\"📹 Input: {video_path_coding_vba}\")\n",
    "    print(f\"📄 Output: {output_video_coding_vba}\")\n",
    "    \n",
    "    # Process the video with enhanced settings\n",
    "    result_path = process_video_with_frame_differencing(\n",
    "        video_path=video_path_coding_vba,\n",
    "        output_markdown_path=output_video_coding_vba,\n",
    "        difference_threshold=ENHANCED_CONFIG['difference_threshold'],\n",
    "        min_frame_interval=ENHANCED_CONFIG['min_frame_interval'],\n",
    "        max_frames=ENHANCED_CONFIG['max_frames'],\n",
    "        cleanup_temp_files=ENHANCED_CONFIG['cleanup_temp_files'],\n",
    "        username=ENHANCED_CONFIG['username'],\n",
    "        resize_factor=ENHANCED_CONFIG['resize_factor'],\n",
    "        max_retries=ENHANCED_CONFIG['max_retries'],\n",
    "        sleep_duration=ENHANCED_CONFIG['sleep_duration']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n🎉 SUCCESS! Enhanced video analysis completed.\")\n",
    "    print(f\"📄 Report saved to: {result_path}\")\n",
    "    print(f\"💰 Cost optimization: Only {ENHANCED_CONFIG['max_frames']} frames analyzed\")\n",
    "    print(f\"🛡️ Rate limiting protection: {ENHANCED_CONFIG['max_retries']} retries, {ENHANCED_CONFIG['sleep_duration']}s sleep\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error during enhanced processing: {str(e)}\")\n",
    "    print(\"Please check your video file path and configuration.\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"💡 RATE LIMITING TIPS:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"• Current API limit: 0.6 queries/minute (1 query every ~100 seconds)\")\n",
    "print(f\"• Sleep duration: {ENHANCED_CONFIG['sleep_duration']}s provides buffer for rate limiting\")\n",
    "print(f\"• Max retries: {ENHANCED_CONFIG['max_retries']} attempts per frame\")\n",
    "print(f\"• Frames reduced to {ENHANCED_CONFIG['max_frames']} for faster completion\")\n",
    "print(f\"• Processing will automatically retry failed frames after rate limit cooldown\")\n",
    "print(f\"• Monitor console output for retry status and progress\")\n",
    "\n",
    "# Uncomment to run a quick test with just 3 frames:\n",
    "# test_result = process_video_with_frame_differencing(\n",
    "#     video_path=video_path_coding_vba,\n",
    "#     output_markdown_path=\"./Outputs/test_analysis.md\",\n",
    "#     max_frames=3,\n",
    "#     max_retries=2,\n",
    "#     sleep_duration=70\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9699cfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 TESTING: High-Quality Frame Extraction\n",
      "==================================================\n",
      "📹 Analyzing video: CodingVBA_sample.mp4\n",
      "Video info: 52697 frames, 59.99 FPS, 878.5s duration\n",
      "Processing frames for significant changes...\n",
      "Significant frame found: Frame 723, Time: 12.05s, Change: 0.165\n",
      "Significant frame found: Frame 728, Time: 12.14s, Change: 0.112\n",
      "Progress: 1.9% (1000/52697)\n",
      "Progress: 3.8% (2000/52697)\n",
      "Progress: 5.7% (3000/52697)\n",
      "Progress: 7.6% (4000/52697)\n",
      "Significant frame found: Frame 4777, Time: 79.63s, Change: 0.772\n",
      "Significant frame found: Frame 4860, Time: 81.02s, Change: 0.156\n",
      "Progress: 9.5% (5000/52697)\n",
      "Significant frame found: Frame 5025, Time: 83.77s, Change: 0.127\n",
      "Significant frame found: Frame 5154, Time: 85.92s, Change: 0.177\n",
      "Progress: 11.4% (6000/52697)\n",
      "Progress: 13.3% (7000/52697)\n",
      "Progress: 15.2% (8000/52697)\n",
      "Significant frame found: Frame 8581, Time: 143.05s, Change: 0.140\n",
      "Significant frame found: Frame 8706, Time: 145.13s, Change: 0.248\n",
      "Progress: 17.1% (9000/52697)\n",
      "Significant frame found: Frame 9797, Time: 163.32s, Change: 0.102\n",
      "Progress: 19.0% (10000/52697)\n",
      "Significant frame found: Frame 10307, Time: 171.82s, Change: 0.105\n",
      "Progress: 20.9% (11000/52697)\n",
      "Progress: 22.8% (12000/52697)\n",
      "Progress: 24.7% (13000/52697)\n",
      "Significant frame found: Frame 13111, Time: 218.57s, Change: 0.143\n",
      "Progress: 26.6% (14000/52697)\n",
      "Significant frame found: Frame 14647, Time: 244.17s, Change: 0.157\n",
      "Progress: 28.5% (15000/52697)\n",
      "Significant frame found: Frame 15147, Time: 252.51s, Change: 0.232\n",
      "Significant frame found: Frame 15659, Time: 261.04s, Change: 0.204\n",
      "Significant frame found: Frame 15824, Time: 263.79s, Change: 0.249\n",
      "Progress: 30.4% (16000/52697)\n",
      "Significant frame found: Frame 16259, Time: 271.05s, Change: 0.135\n",
      "Progress: 32.3% (17000/52697)\n",
      "Progress: 34.2% (18000/52697)\n",
      "Progress: 36.1% (19000/52697)\n",
      "Progress: 38.0% (20000/52697)\n",
      "Progress: 39.9% (21000/52697)\n",
      "Progress: 41.7% (22000/52697)\n",
      "Progress: 43.6% (23000/52697)\n",
      "Progress: 45.5% (24000/52697)\n",
      "Significant frame found: Frame 24440, Time: 407.43s, Change: 0.119\n",
      "Significant frame found: Frame 24445, Time: 407.51s, Change: 0.143\n",
      "Significant frame found: Frame 24491, Time: 408.28s, Change: 0.102\n",
      "Progress: 47.4% (25000/52697)\n",
      "Progress: 49.3% (26000/52697)\n",
      "Significant frame found: Frame 26841, Time: 447.45s, Change: 0.248\n",
      "Progress: 51.2% (27000/52697)\n",
      "Significant frame found: Frame 27211, Time: 453.62s, Change: 0.121\n",
      "Significant frame found: Frame 27216, Time: 453.70s, Change: 0.133\n",
      "Progress: 53.1% (28000/52697)\n",
      "Progress: 55.0% (29000/52697)\n",
      "Progress: 56.9% (30000/52697)\n",
      "Progress: 58.8% (31000/52697)\n",
      "Progress: 60.7% (32000/52697)\n",
      "Progress: 62.6% (33000/52697)\n",
      "Significant frame found: Frame 33507, Time: 558.58s, Change: 0.233\n",
      "Significant frame found: Frame 33555, Time: 559.38s, Change: 0.101\n",
      "Progress: 64.5% (34000/52697)\n",
      "Progress: 66.4% (35000/52697)\n",
      "Significant frame found: Frame 35361, Time: 589.48s, Change: 0.259\n",
      "Significant frame found: Frame 35434, Time: 590.70s, Change: 0.108\n",
      "Progress: 68.3% (36000/52697)\n",
      "Progress: 70.2% (37000/52697)\n",
      "Significant frame found: Frame 37932, Time: 632.34s, Change: 0.246\n",
      "Significant frame found: Frame 37999, Time: 633.46s, Change: 0.118\n",
      "Progress: 72.1% (38000/52697)\n",
      "Significant frame found: Frame 38569, Time: 642.96s, Change: 0.247\n",
      "Significant frame found: Frame 38645, Time: 644.23s, Change: 0.118\n",
      "Significant frame found: Frame 38893, Time: 648.36s, Change: 0.116\n",
      "Significant frame found: Frame 38898, Time: 648.45s, Change: 0.160\n",
      "Significant frame found: Frame 38917, Time: 648.76s, Change: 0.131\n",
      "Significant frame found: Frame 38929, Time: 648.96s, Change: 0.102\n",
      "Progress: 74.0% (39000/52697)\n",
      "Progress: 75.9% (40000/52697)\n",
      "Significant frame found: Frame 40822, Time: 680.52s, Change: 0.284\n",
      "Progress: 77.8% (41000/52697)\n",
      "Significant frame found: Frame 41815, Time: 697.08s, Change: 0.114\n",
      "Progress: 79.7% (42000/52697)\n",
      "Progress: 81.6% (43000/52697)\n",
      "Progress: 83.5% (44000/52697)\n",
      "Progress: 85.4% (45000/52697)\n",
      "Progress: 87.3% (46000/52697)\n",
      "Progress: 89.2% (47000/52697)\n",
      "Progress: 91.1% (48000/52697)\n",
      "Progress: 93.0% (49000/52697)\n",
      "Progress: 94.9% (50000/52697)\n",
      "Progress: 96.8% (51000/52697)\n",
      "Significant frame found: Frame 51410, Time: 857.03s, Change: 0.276\n",
      "Significant frame found: Frame 51486, Time: 858.30s, Change: 0.108\n",
      "Significant frame found: Frame 51968, Time: 866.33s, Change: 0.287\n",
      "Reached maximum frames limit (40)\n",
      "Extracted 40 significant frame timestamps from 52697 total frames\n",
      "Frame reduction: 99.9%\n",
      "💾 Saving frames to: ./quick_test_frames\n",
      "Extracting 40 high-quality frames from original video...\n",
      "  Extracted 10/40 high-quality frames\n",
      "  Extracted 20/40 high-quality frames\n",
      "  Extracted 30/40 high-quality frames\n",
      "  Extracted 40/40 high-quality frames\n",
      "Successfully saved 40 high-quality frame images to ./quick_test_frames\n",
      "✅ Successfully extracted 40 frames\n",
      "📁 Frames saved in: ./quick_test_frames\n",
      "🎉 Quick test completed: 40 frames extracted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'video_file': 'CodingVBA_sample.mp4',\n",
       " 'frames_extracted': 40,\n",
       " 'output_directory': './quick_test_frames',\n",
       " 'video_metadata': {'fps': 59.986340093722134,\n",
       "  'total_frames': 52697,\n",
       "  'duration': 878.4833333333333,\n",
       "  'video_path': './VidRecordings/CodingVBA_sample.mp4'},\n",
       " 'frame_details': [{'frame_number': 0,\n",
       "   'timestamp': 0.0,\n",
       "   'difference_score': 1.0,\n",
       "   'filename': 'frame_000000_diff_1.000.png'},\n",
       "  {'frame_number': 723,\n",
       "   'timestamp': 12.052743989221398,\n",
       "   'difference_score': 0.16497974537037038,\n",
       "   'filename': 'frame_000723_diff_0.165.png'},\n",
       "  {'frame_number': 728,\n",
       "   'timestamp': 12.13609629896705,\n",
       "   'difference_score': 0.1115113811728395,\n",
       "   'filename': 'frame_000728_diff_0.112.png'},\n",
       "  {'frame_number': 4777,\n",
       "   'timestamp': 79.63479673099671,\n",
       "   'difference_score': 0.7715345293209876,\n",
       "   'filename': 'frame_004777_diff_0.772.png'},\n",
       "  {'frame_number': 4860,\n",
       "   'timestamp': 81.01844507277454,\n",
       "   'difference_score': 0.15628954475308643,\n",
       "   'filename': 'frame_004860_diff_0.156.png'},\n",
       "  {'frame_number': 5025,\n",
       "   'timestamp': 83.76907129438108,\n",
       "   'difference_score': 0.12735725308641976,\n",
       "   'filename': 'frame_005025_diff_0.127.png'},\n",
       "  {'frame_number': 5154,\n",
       "   'timestamp': 85.91956088581892,\n",
       "   'difference_score': 0.17656780478395062,\n",
       "   'filename': 'frame_005154_diff_0.177.png'},\n",
       "  {'frame_number': 8581,\n",
       "   'timestamp': 143.04923398548937,\n",
       "   'difference_score': 0.1402025462962963,\n",
       "   'filename': 'frame_008581_diff_0.140.png'},\n",
       "  {'frame_number': 8706,\n",
       "   'timestamp': 145.1330417291307,\n",
       "   'difference_score': 0.24847270447530864,\n",
       "   'filename': 'frame_008706_diff_0.248.png'},\n",
       "  {'frame_number': 9797,\n",
       "   'timestamp': 163.32051571563213,\n",
       "   'difference_score': 0.10171055169753086,\n",
       "   'filename': 'frame_009797_diff_0.102.png'},\n",
       "  {'frame_number': 10307,\n",
       "   'timestamp': 171.82245130968872,\n",
       "   'difference_score': 0.10495418595679012,\n",
       "   'filename': 'frame_010307_diff_0.105.png'},\n",
       "  {'frame_number': 13111,\n",
       "   'timestamp': 218.56642661505083,\n",
       "   'difference_score': 0.14290605709876544,\n",
       "   'filename': 'frame_013111_diff_0.143.png'},\n",
       "  {'frame_number': 14647,\n",
       "   'timestamp': 244.17225616891537,\n",
       "   'difference_score': 0.15680748456790122,\n",
       "   'filename': 'frame_014647_diff_0.157.png'},\n",
       "  {'frame_number': 15147,\n",
       "   'timestamp': 252.50748714348066,\n",
       "   'difference_score': 0.23238136574074075,\n",
       "   'filename': 'frame_015147_diff_0.232.png'},\n",
       "  {'frame_number': 15659,\n",
       "   'timestamp': 261.0427636614355,\n",
       "   'difference_score': 0.20370081018518518,\n",
       "   'filename': 'frame_015659_diff_0.204.png'},\n",
       "  {'frame_number': 15824,\n",
       "   'timestamp': 263.79338988304204,\n",
       "   'difference_score': 0.24944733796296295,\n",
       "   'filename': 'frame_015824_diff_0.249.png'},\n",
       "  {'frame_number': 16259,\n",
       "   'timestamp': 271.0450408309138,\n",
       "   'difference_score': 0.1346503665123457,\n",
       "   'filename': 'frame_016259_diff_0.135.png'},\n",
       "  {'frame_number': 24440,\n",
       "   'timestamp': 407.42609003675096,\n",
       "   'difference_score': 0.11882908950617284,\n",
       "   'filename': 'frame_024440_diff_0.119.png'},\n",
       "  {'frame_number': 24445,\n",
       "   'timestamp': 407.50944234649666,\n",
       "   'difference_score': 0.14324122299382716,\n",
       "   'filename': 'frame_024445_diff_0.143.png'},\n",
       "  {'frame_number': 24491,\n",
       "   'timestamp': 408.27628359615665,\n",
       "   'difference_score': 0.10164834104938271,\n",
       "   'filename': 'frame_024491_diff_0.102.png'},\n",
       "  {'frame_number': 26841,\n",
       "   'timestamp': 447.45186917661346,\n",
       "   'difference_score': 0.24751157407407406,\n",
       "   'filename': 'frame_026841_diff_0.248.png'},\n",
       "  {'frame_number': 27211,\n",
       "   'timestamp': 453.61994009779175,\n",
       "   'difference_score': 0.1208984375,\n",
       "   'filename': 'frame_027211_diff_0.121.png'},\n",
       "  {'frame_number': 27216,\n",
       "   'timestamp': 453.70329240753745,\n",
       "   'difference_score': 0.13321180555555556,\n",
       "   'filename': 'frame_027216_diff_0.133.png'},\n",
       "  {'frame_number': 33507,\n",
       "   'timestamp': 558.5771685295178,\n",
       "   'difference_score': 0.23296730324074075,\n",
       "   'filename': 'frame_033507_diff_0.233.png'},\n",
       "  {'frame_number': 33555,\n",
       "   'timestamp': 559.3773507030761,\n",
       "   'difference_score': 0.10139612268518519,\n",
       "   'filename': 'frame_033555_diff_0.101.png'},\n",
       "  {'frame_number': 35361,\n",
       "   'timestamp': 589.4842049832059,\n",
       "   'difference_score': 0.2591772762345679,\n",
       "   'filename': 'frame_035361_diff_0.259.png'},\n",
       "  {'frame_number': 35434,\n",
       "   'timestamp': 590.7011487054924,\n",
       "   'difference_score': 0.10808063271604938,\n",
       "   'filename': 'frame_035434_diff_0.108.png'},\n",
       "  {'frame_number': 37932,\n",
       "   'timestamp': 632.3439626544206,\n",
       "   'difference_score': 0.24621431327160495,\n",
       "   'filename': 'frame_037932_diff_0.246.png'},\n",
       "  {'frame_number': 37999,\n",
       "   'timestamp': 633.4608836050123,\n",
       "   'difference_score': 0.11807291666666667,\n",
       "   'filename': 'frame_037999_diff_0.118.png'},\n",
       "  {'frame_number': 38569,\n",
       "   'timestamp': 642.9630469160168,\n",
       "   'difference_score': 0.24658805941358025,\n",
       "   'filename': 'frame_038569_diff_0.247.png'},\n",
       "  {'frame_number': 38645,\n",
       "   'timestamp': 644.2300020241506,\n",
       "   'difference_score': 0.11816743827160493,\n",
       "   'filename': 'frame_038645_diff_0.118.png'},\n",
       "  {'frame_number': 38893,\n",
       "   'timestamp': 648.3642765875351,\n",
       "   'difference_score': 0.11566840277777778,\n",
       "   'filename': 'frame_038893_diff_0.116.png'},\n",
       "  {'frame_number': 38898,\n",
       "   'timestamp': 648.4476288972807,\n",
       "   'difference_score': 0.16047164351851853,\n",
       "   'filename': 'frame_038898_diff_0.160.png'},\n",
       "  {'frame_number': 38917,\n",
       "   'timestamp': 648.7643676743141,\n",
       "   'difference_score': 0.1310175540123457,\n",
       "   'filename': 'frame_038917_diff_0.131.png'},\n",
       "  {'frame_number': 38929,\n",
       "   'timestamp': 648.9644132177037,\n",
       "   'difference_score': 0.1018581211419753,\n",
       "   'filename': 'frame_038929_diff_0.102.png'},\n",
       "  {'frame_number': 40822,\n",
       "   'timestamp': 680.5215976874078,\n",
       "   'difference_score': 0.2841473765432099,\n",
       "   'filename': 'frame_040822_diff_0.284.png'},\n",
       "  {'frame_number': 41815,\n",
       "   'timestamp': 697.0753664028946,\n",
       "   'difference_score': 0.11400125385802469,\n",
       "   'filename': 'frame_041815_diff_0.114.png'},\n",
       "  {'frame_number': 51410,\n",
       "   'timestamp': 857.0284488048023,\n",
       "   'difference_score': 0.27606819058641974,\n",
       "   'filename': 'frame_051410_diff_0.276.png'},\n",
       "  {'frame_number': 51486,\n",
       "   'timestamp': 858.2954039129362,\n",
       "   'difference_score': 0.1083714313271605,\n",
       "   'filename': 'frame_051486_diff_0.108.png'},\n",
       "  {'frame_number': 51968,\n",
       "   'timestamp': 866.3305665724172,\n",
       "   'difference_score': 0.2868701774691358,\n",
       "   'filename': 'frame_051968_diff_0.287.png'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_extract_significant_frames_only(\n",
    "    video_path: str,\n",
    "    output_dir: str = \"./test_SignificantImages\",\n",
    "    difference_threshold: float = 0.1,\n",
    "    min_frame_interval: int = 5,\n",
    "    max_frames: int = 20,\n",
    "    resize_factor: float = 1\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Test function to extract and save significant frames only.\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to input video\n",
    "        output_dir: Directory to save extracted frames\n",
    "        difference_threshold: Threshold for frame difference detection\n",
    "        min_frame_interval: Minimum frames between significant frames\n",
    "        max_frames: Maximum frames to extract\n",
    "        resize_factor: Factor for processing speed (doesn't affect output quality)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Summary of extraction results\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🧪 TESTING: High-Quality Frame Extraction\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Extract significant frame metadata\n",
    "        print(f\"📹 Analyzing video: {os.path.basename(video_path)}\")\n",
    "        frame_metadata, video_metadata = extract_significant_frames(\n",
    "            video_path=video_path,\n",
    "            difference_threshold=difference_threshold,\n",
    "            min_frame_interval=min_frame_interval,\n",
    "            max_frames=max_frames,\n",
    "            resize_factor=resize_factor\n",
    "        )\n",
    "        \n",
    "        if not frame_metadata:\n",
    "            return {\"status\": \"failed\", \"reason\": \"No significant frames found\"}\n",
    "        \n",
    "        # Step 2: Extract high-quality frames\n",
    "        print(f\"💾 Saving frames to: {output_dir}\")\n",
    "        frame_paths = extract_high_quality_frames_from_video(\n",
    "            video_path=video_path,\n",
    "            frame_metadata=frame_metadata,\n",
    "            output_dir=output_dir\n",
    "        )\n",
    "        \n",
    "        # Prepare results summary\n",
    "        results = {\n",
    "            \"status\": \"success\",\n",
    "            \"video_file\": os.path.basename(video_path),\n",
    "            \"frames_extracted\": len(frame_paths),\n",
    "            \"output_directory\": output_dir,\n",
    "            \"video_metadata\": video_metadata,\n",
    "            \"frame_details\": [\n",
    "                {\n",
    "                    \"frame_number\": frame_num,\n",
    "                    \"timestamp\": timestamp,\n",
    "                    \"difference_score\": diff_score,\n",
    "                    \"filename\": os.path.basename(frame_paths[i]) if i < len(frame_paths) else None\n",
    "                }\n",
    "                for i, (frame_num, timestamp, diff_score) in enumerate(frame_metadata)\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        print(f\"✅ Successfully extracted {len(frame_paths)} frames\")\n",
    "        print(f\"📁 Frames saved in: {output_dir}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"status\": \"failed\", \"reason\": str(e)}\n",
    "\n",
    "# Quick test function with minimal parameters\n",
    "def quick_frame_test(video_path: str, max_frames: int = 10) -> None:\n",
    "    \"\"\"Quick test with default settings.\"\"\"\n",
    "    results = test_extract_significant_frames_only(\n",
    "        video_path=video_path,\n",
    "        max_frames=max_frames,\n",
    "        output_dir=\"./quick_test_frames\"\n",
    "    )\n",
    "    \n",
    "    if results[\"status\"] == \"success\":\n",
    "        print(f\"🎉 Quick test completed: {results['frames_extracted']} frames extracted\")\n",
    "    else:\n",
    "        print(f\"❌ Quick test failed: {results['reason']}\")\n",
    "        \n",
    "    return results\n",
    "\n",
    "quick_frame_test(video_path_coding_vba, max_frames=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab78f8f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
